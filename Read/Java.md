# 1.设计模式

## 1.1创建者模式 

创建型模式的主要关注点是“怎样创建对象？”，它的主要特点是“将对象的创建与使用分离”。

这样可以降低系统的耦合度，使用者不需要关注对象的创建细节。

创建型模式分为：

* 单例模式
* 工厂方法模式
* 抽象工程模式
* 原型模式
* 建造者模式

### 1.1.1单例设计模式

单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。

这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。

#### 1.1.1.1实现方法

**单例设计模式分类两种：**

​	**饿汉式：类加载就会导致该单实例对象被创建**	

​	**懒汉式：类加载不会导致该单实例对象被创建，而是首次使用该对象时才会创建**

##### 1.1.1.1.1饿汉式-静态变量

```java
public class Singleton {
    private Singleton(){}
    private static Singleton instance = new Singleton();
    public static Singleton getInstance(){
        return instance;
    }
}
```

##### 1.1.1.1.2饿汉式-静态代码块

```java
public class Singleton_e2 {
    private Singleton_e2(){}
    private static Singleton_e2 instance;
    static {
        instance = new Singleton_e2();
    }
    public static Singleton_e2 getInstance() {
        return instance;
    }
}
```

instance对象是随着类的加载而创建的。如果该对象足够大的话，而一直没有使用就会造成内存的浪费。

##### 1.1.1.1.3懒汉式-线程不安全

```java
public class Singleton_l1 {
    private Singleton_l1(){}
    private static Singleton_l1 instance;
    public static Singleton_l1 getInstance() {
        if (instance == null){
            instance = new Singleton_l1();
        }
        return instance;
    }
}
```

##### 1.1.1.1.4懒汉式-线程安全

```java
public class Singleton_l1 {
    private Singleton_l1(){}
    private static Singleton_l1 instance;
    public static synchronized Singleton_l1 getInstance() {
        if (instance == null){
            instance = new Singleton_l1();
        }
        return instance;
    }
}
```

该方式也实现了懒加载效果，同时又解决了线程安全问题。但是在getInstance()方法上添加了synchronized关键字，导致该方法的执行效果特别低。从上面代码我们可以看出，其实就是在初始化instance的时候才会出现线程安全问题，一旦初始化完成就不存在了。

##### 1.1.1.1.5懒汉式-双重检查锁

```java
public class Singleton_l2 {
    private Singleton_l2(){}
    private static volatile Singleton_l2 instance;
    public static Singleton_l2 getInstance(){
        if (instance == null) {
            synchronized (Singleton_l2.class) {
                if (instance == null) {
                    instance = new Singleton_l2();
                }
            }
        }
        return instance;
    }
}
```

双重检查锁模式是一种非常好的单例实现模式，解决了单例、性能、线程安全问题，上面的双重检测锁模式看上去完美无缺，其实是存在问题，在多线程的情况下，可能会出现空指针问题，出现问题的原因是JVM在实例化对象的时候会进行优化和指令重排序操作。

要解决双重检查锁模式带来空指针异常的问题，只需要使用 `volatile` 关键字, `volatile` 关键字可以保证可见性和有序性。

##### 1.1.1.1.6懒汉式-静态内部类

静态内部类单例模式中实例由内部类创建，由于 JVM 在加载外部类的过程中, 是不会加载静态内部类的, 只有内部类的属性/方法被调用时才会被加载, 并初始化其静态属性。静态属性由于被 `static` 修饰，保证只被实例化一次，并且严格保证实例化顺序。

```java
public class Singleton_l3 {
    private Singleton_l3(){} 
    private static class SingletonHolder{
        private static final Singleton_l3 INSTANCE = new Singleton_l3();
    }
    public static Singleton_l3 getInstance() {
        return SingletonHolder.INSTANCE;
    }
}
```

##### 1.1.1.1.7枚举

枚举类实现单例模式是极力推荐的单例实现模式，因为枚举类型是线程安全的，并且只会装载一次，设计者充分的利用了枚举的这个特性来实现单例模式，枚举的写法非常简单，而且枚举类型是所用单例实现中唯一一种不会被破坏的单例实现模式。

```java
public enum Singleton{
    INSTANCE;
}
```

#### 1.1.1.2破坏及解决方法

##### 1.1.1.2.1序列化

序列化会通过反射调用无参数的构造方法创建一个新的对象。

```java
public class Singleton implements Serializable {
    //私有构造方法
    private Singleton() {}
    private static class SingletonHolder {
        private static final Singleton INSTANCE = new Singleton();
    }
    //对外提供静态方法获取该对象
    public static Singleton getInstance() {
        return SingletonHolder.INSTANCE;
    }
}
```

解决方法：在Singleton类中添加`readResolve()`方法，在反序列化时被反射调用，如果定义了这个方法，就返回这个方法的值，如果没有定义，则返回新new出来的对象。

```java
public class Singleton implements Serializable {
    //私有构造方法
    private Singleton() {}
    private static class SingletonHolder {
        private static final Singleton INSTANCE = new Singleton();
    }
    //对外提供静态方法获取该对象
    public static Singleton getInstance() {
        return SingletonHolder.INSTANCE;
    }
    private Object readResolve() {
        return SingletonHolder.INSTANCE;
    }
}
```

##### 1.1.1.2.2反射

```java
public class Singleton {
    private Singleton() {
        if(instance != null) {
            throw new RuntimeException();
        }
    }
    private static volatile Singleton instance;
    public static Singleton getInstance() {
    }
}
```

解决方法：当通过反射方式调用构造方法进行创建创建时，直接抛异常。不运行此中操作。

### 1.1.2 Factory Method（工厂方法）

**意图：**

定义一个用于创建对象的接口，让子类决定实例化哪一个类。Factory Method 使一个类的实例化延迟到其子类。

**适用性：**

当一个类不知道它所必须创建的对象的类的时候。

当一个类希望由它的子类来指定它所创建的对象的时候。

当类将创建对象的职责委托给多个帮助子类中的某一个，并且你希望将哪一个帮助子类是代理者这一信息局部化的时候。

### 1.1.3 Abstract Factory（抽象工厂）

**意图：**

提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。

**适用性：**

一个系统要独立于它的产品的创建、组合和表示时。

一个系统要由多个产品系列中的一个来配置时。

当你要强调一系列相关的产品对象的设计以便进行联合使用时。

当你提供一个产品类库，而只想显示它们的接口而不是实现时。

### 1.1.4 Builder（建造者）

**意图：**

将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。

**适用性：**

当创建复杂对象的算法应该独立于该对象的组成部分以及它们的装配方式时。

当构造过程必须允许被构造的对象有不同的表示时。

### 1.1.5 Prototype（原型）

**意图：**

用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。

**适用性：**

当要实例化的类是在运行时刻指定时，例如，通过动态装载；或者

为了避免创建一个与产品类层次平行的工厂类层次时；或者

当一个类的实例只能有几个不同状态组合中的一种时。建立相应数目的原型并克隆它们可能比每次用合适的状态手工实例化该类更方便一些。

## 1.2 结构型模式

### 1.2.1 Adapter Class/Object（适配器）

**意图：**

将一个类的接口转换成客户希望的另外一个接口。Adapter 模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。

**适用性：**

你想使用一个已经存在的类，而它的接口不符合你的需求。

你想创建一个可以复用的类，该类可以与其他不相关的类或不可预见的类（即那些接口可能不一定兼容的类）协同工作。

（仅适用于对象Adapter ）你想使用一些已经存在的子类，但是不可能对每一个都进行子类化以匹配它们的接口。对象适配器可以适配它的父类接口。

### 1.2.2 Decorator（装饰）

**意图：**

动态地给一个对象添加一些额外的职责。就增加功能来说，Decorator 模式相比生成子类更为灵活。

**适用性：**

在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责。

处理那些可以撤消的职责。

当不能采用生成子类的方法进行扩充时。一种情况是，可能有大量独立的扩展，为支持每一种组合将产生大量的子类，使得子类数目呈爆炸性增长。另一种情况可能是因为类定义被隐藏，或类定义不能用于生成子类。

### 1.2.3 Proxy（代理）

**意图：**

为其他对象提供一种代理以控制对这个对象的访问。

**适用性：**

在需要用比较通用和复杂的对象指针代替简单的指针的时候，使用Proxy模式。下面是一 些可以使用Proxy 模式常见情况：

- 远程代理（Remote Proxy ）为一个对象在不同的地址空间提供局部代表。NEXTSTEP[Add94] 使用NXProxy 类实现了这一目的。Coplien[Cop92] 称这种代理为“大使” （Ambassador ）。
- 虚代理（Virtual Proxy ）根据需要创建开销很大的对象。在动机一节描述的ImageProxy 就是这样一种代理的例子。
- 保护代理（Protection Proxy ）控制对原始对象的访问。保护代理用于对象应该有不同 的访问权限的时候。例如，在Choices 操作系统[ CIRM93]中KemelProxies为操作系统对象提供 了访问保护。
- 智能指引（Smart Reference ）取代了简单的指针，它在访问对象时执行一些附加操作。它的典型用途包括：

对指向实际对象的引用计数，这样当该对象没有引用时，可以自动释放它(也称为SmartPointers[Ede92 ] )。

当第一次引用一个持久对象时，将它装入内存。

在访问一个实际对象前，检查是否已经锁定了它，以确保其他对象不能改变它。

## 1.3 行为型模式

### 1.3.1. Interpreter（解释器）

**意图：**

给定一个语言，定义它的文法的一种表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。

**适用性：**

当有一个语言需要解释执行, 并且你可将该语言中的句子表示为一个抽象语法树时，可使用解释器模式。而当存在以下情况时该模式效果最好：

该文法简单对于复杂的文法, 文法的类层次变得庞大而无法管理。此时语法分析程序生成器这样的工具是更好的选择。它们无需构建抽象语法树即可解释表达式, 这样可以节省空间而且还可能节省时间。

效率不是一个关键问题最高效的解释器通常不是通过直接解释语法分析树实现的, 而是首先将它们转换成另一种形式。例如，正则表达式通常被转换成状态机。但即使在这种情况下, 转换器仍可用解释器模式实现, 该模式仍是有用的。

### 1.3.2 Template Method（模板方法）

**意图：**

定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。TemplateMethod 使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。

**适用性：**

一次性实现一个算法的不变的部分，并将可变的行为留给子类来实现。

各子类中公共的行为应被提取出来并集中到一个公共父类中以避免代码重复。这是Opdyke 和Johnson 所描述过的“重分解以一般化”的一个很好的例子[ OJ93 ]。首先识别现有代码中的不同之处，并且将不同之处分离为新的操作。最后，用一个调用这些新的操作的模板方法来替换这些不同的代码。

控制子类扩展。模板方法只在特定点调用“hook ”操作（参见效果一节），这样就只允许在这些点进行扩展。

### 1.3.3 Chain of Responsibility（责任链）

**意图：**

使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。

**适用性：**

有多个的对象可以处理一个请求，哪个对象处理该请求运行时刻自动确定。

你想在不明确指定接收者的情况下，向多个对象中的一个提交一个请求。

可处理一个请求的对象集合应被动态指定

## 1.4 设计原则

### **一、单一职责原则**

就一个类而言，应该仅有一个引起它变化的原因。

如果一个类承担的职责过多，就等于把这些职责耦合在一起，一个职责的变化可能会削弱或者抑制这个类完成其他职责的能力。这种耦合会导致脆弱他的设计，当变化发生时，设计会遭受到意想不到的破坏；软件设计真正要做的许多内容就是发现职责并把那些职责相互分离。

### **二、开放-封闭原则**

软件实体应该可以扩展，但不可修改。该原则是面向对象设计的核心所在，遵循这个原则可以带来面向对象技术所声称的可维护、可扩展、可复用、灵活性好。

设计人员必须对于他设计的模块应该对哪种变化封闭做出选择，必须先猜测出最有可能发生的变化种类，然后构造抽象来隔离那些变化。最初编写程序时假设变化不会发生，当变化发生时，就创建抽象来隔离以后发生的同类变化，拒绝不成熟的抽象。

### **三、里氏代换原则**

子类型必须能够替换掉它们的父类型。由于子类型的可替换性才使得使用父类类型的模块在无需修改的情况下就可以扩展。

### **四、依赖倒转原则**

高层模块不应该依赖低层模块，两个都应该依赖抽象；抽象不应该依赖细节，细节应该依赖抽象。

要针对接口编程，不要针对实现编程。该原则可以说是面向对象设计的标志，编写时考虑的是如何对抽象编程而不是针对细节编程，即程序中所有的依赖关系都是终止于抽象类或者接口。

### **五、迪迷特原则（最少知识原则）**

如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用；如果其中一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。

该原则其根本思想，是强调了类之间的松耦合；类之间的耦合越弱，越利于复用，一个处在弱耦合的类被修改，不会对有关系的类造成波及。在类的结构设计上，每一个类都应当尽量降低成员的访问权限。

### **六、合成/聚合复用原则**

尽量使用合成/聚合，尽量不要使用类继承。

聚合表示一种弱的“拥有”关系，体现的是A对象可以包含B对象，但B对象不是A对象的一部分；合成则是一种强的“拥有”关系，体现了严格的部分和整体的关系，部分和整体的生命周期一样。

优先使用对象的合成/聚合将有助于你保持每个类被封装，并被击中在单个任务上，这样类和类继承层次会保持较小规模，并且不太可能增长为不可控制的庞然大物。

# 2. Linux

## 2.1 文件系统和目录结构

- **/bin：** 存放二进制可执行文件(ls、cat、mkdir 等)，常用命令一般都在这里；
- **/etc：** 存放系统管理和配置文件；
- **/home：** 存放所有用户文件的根目录，是用户主目录的基点，比如用户 user 的主目录就是/home/user，可以用~user 表示；
- **/usr ：** 用于存放系统应用程序；
- **/opt：** 额外安装的可选应用程序包所放置的位置。一般情况下，我们可以把 tomcat 等都安装到这里；
- **/proc：** 虚拟文件系统目录，是系统内存的映射。可直接访问这个目录来获取系统信息；
- **/root：** 超级用户（系统管理员）的主目录（特权阶级^o^）；
- **/sbin:** 存放二进制可执行文件，只有 root 才能访问。这里存放的是系统管理员使用的系统级别的管理命令和程序。如 ifconfig 等；
- **/dev：** 用于存放设备文件；
- **/mnt：** 系统管理员安装临时文件系统的安装点，系统提供这个目录是让用户临时挂载其他的文件系统；
- **/boot：** 存放用于系统引导时使用的各种文件；
- **/lib ：** 存放着和系统运行相关的库文件 ；
- **/tmp：** 用于存放各种临时文件，是公用的临时文件存储点；
- **/var：** 用于存放运行时需要改变数据的文件，也是某些大文件的溢出区，比方说各种服务的日志文件（系统启动日志等。）等；
- **/lost+found：** 这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows 下叫什么.chk）就在这里。

## 2.2 VIM编辑器

**一般模式**  

nyy 复制n行       p 粘贴        ndd 删除n行      u 撤销     x剪切   i进入编辑模式

y￥复制当前字符到行尾  y^复制当前字符到行头  yw复制当前单词    dw删除当前单词

**命令模式**

:w保存  :wq保存退出  :q!强制退出

## 2.3 常用基本命令

### 2.3.1 帮助命令

man[命令] 

help[命令] （shell内置命令的帮助信息）

### 2.3.2 文件目录类

pwd 显示当前工作目录的绝对路径

cd 进入目录

ls 列出目录的内容 -a显示所有 -l 文件的属性和权限都显示出来

mkdir 创建文件夹  -p创建没有的嵌套文件目录

rmdir 删除文件夹 

touch 创建文件

cp 当前 + 目标  复制文件或目录 -r递归复制每个文件夹

rm 删除文件或目录 -r 递归 -f强制

mv 移动文件或目录

cat 查看文件内容

more 文件内容分屏查看器

less 分屏显示文件内容 根据显示需要加载内容

echo 输出

head 显示文件开始几行

tail 显示文件最后几行

ln -s 原文件目录 软链接名

history 查看执行过的历史命令

### 2.3.3 时间日期命令

date +%Y +%m +%d

cal 日历

### 2.3.4 用户权限类

useradd 添加新用户 -g 分组

passwd +用户  添加密码

cat /etc/passwd 查看所有用户

su 切换用户

sudo 设置root权限

userdel 删除用户

usermod -g 用户组 用户名 修改用户组

### 2.3.5 文件权限类

文件类型+属主权限+属组权限+其他用户权限 读写执行

ls -ll   文件类型和权限 链接数 文件属主 文件属组 文件大小 建立或最近修改的时间 文件名字

chmod 更改文件权限 

chmod ugoa +-= rwx

chmod 421

### 2.3.6 文件查找类

find -name -user -size 查找文件或者目录

locate 快速定位

grep 选项 查找内容 源文件 过滤查找 查找文件内容

|管道符  ls | grep .txt

2.3.7压缩解压类

gzip gunzip zip unzip

tar -xvf -zcvf 

### 2.3.7 磁盘查看和分区类

du 查看文件或目录的磁盘占用空间

df 查看空余磁盘

lsblk 查看设备挂载情况

mount/umount 挂载/卸载

fdisk 查看磁盘分区详情

### 2.3.8 进程管理类

ps 查看当前进程

kill + 进程号 终止进程

pstree 查看进程树

top 实时监控系统进程状态

netstat 查看网络状态和端口占用信息

### 2.3.9系统定时任务

crontab 分时天月周

# 3. 计算机网络

## 3.1 7层OSI模型

### 3.1.1 应用层

所有能和用户交互产生网络流量的程序

使用的协议：FTP SMTP HTTP

### 3.1.2 表示层

处理两个通信系统中交换信息的表示方式

数据格式变换 + 数据加密解密 + 数据压缩和恢复

### 3.1.3 会话层

向表示层实体提供建立连接并在连接上有序的传输数据

建立、管理、终止会话 + 使用校验点恢复通信

### 3.1.4 传输层

负责端到端的通信，传输单位是报文段或用户数据报。

可靠传输、不可靠传输 + 差错控制 + 流量控制 + 复用分用

### 3.1.5 网络层

主要任务是把分组从源端传到目的端，为分组交换网上的不同主机提供服务。

路由选择 + 流量控制 + 差错控制 + 拥塞控制

### 3.1.6 数据链路层

把网络层传下来的数据组装成帧

成帧 + 差错控制 + 流量控制 + 访问控制

### 3.1.7 物理层

物理媒体上实现比特流的透明传输，传输单位是比特

定义接口特性 + 定义传输模式（单双工）+ 定义传输速率 + 比特同步 + 比特编码

## 3.2 5层参考模型

物理层 比特传输

数据链路层 把网络层传下来的数据报组装成帧

网络层 源主机到目的主机的数据分组路由与转发

传输层 进程间的数据传输

应用层 支持各种网络应用

## 3.3 物理层

物理层解决如何在连接各种计算机的传输媒体上的传输数据比特流，而不是指具体的传输媒体。

主要任务：确定与传输媒体接口有关的特性     **定义标准**

设备 中继器 集线器

## 3.4 数据链路层

为网络层提供服务。

### 3.4.1 封装成帧

在一段数据的前后两部分添加首部和尾部。接收端收到比特流后，根据标记，识别出开始和结束。

帧的数据部分<= MTU（最大传送单元）

组帧方法：字符计数法 + 字符填充法 + 零比特填充法 + 违规编码法

### 3.4.2 差错控制

检错编码 奇偶校验码/循环冗余码

纠错编码 海明码  发现双比特错，纠正单比特错

### 3.4.3 流量控制与可靠传输

数据链路层流量控制：接收方收不下就不回复确认

传输层流量控制手段：接收端给发送端一个窗口公告

停止-等待协议 滑动窗口协议 （后退N帧 选择重传）

超时计时器 控制 超时重传 

## 3.5 浏览器输入url

1.首先，你要在浏览器中输入网址

2.浏览器查找域名的IP地址

浏览器会把输入的域名解析成对应的IP，DNS过程如下：

查找浏览器缓存：因为浏览器一般会缓存DNS记录一段时间，不同的浏览器的时间可能不一样，一般2-30分钟不等，浏览器去查找这些缓存，如果有缓存，直接返回IP，否则下一步
查找系统缓存：浏览器缓存中找不到IP之后，浏览器会进行系统调用(windows中是gethostbyname)，查找本机的hosts文件，如果找到，直接返回IP，否则下一步
查找路由器缓存：如果1，2步都查询无果，则需要借助网络，路由器一般都有自己的DNS缓存，将前面的请求发给路由器，查找ISP服务商缓存的DNS的服务器，如果查找到IP则直接返回，没有的话继续查找
递归查询：如果上述步骤还找不到，则ISP的DNS服务器就会进行递归查询，所谓递归查询就是如果主机所询问的本地域名服务器不知道被查询域名的IP地址，那么本地域名服务器就以DNS客户的身份，向其他根域名服务器继续发送查询请求报文，而不是让该主机自己进行下一步查询。(本地域名服务器地址是通过DHPC协议获取地址，DHPC是负责分配IP地址的)
迭代查询：本地域名服务器采用迭代查询，他先向一个根域名服务器查询。本地域名服务器向根域名服务器的查询一般都是采用迭代查询。所谓迭代查询就是当根域名服务器收到本地域名服务器发出的查询请求报文后，要么告诉本地服务器下一步查询哪一个域名服务器，然后本地域名服务器进行后续的查询。（而不是替代本地域名服务器进行后续查询）
在本例子中：根域名服务器告诉本地域名服务器，下一次查询的顶级域名服务器dns.net的IP地址。本地域名服务器向顶级域名服务器进行查询。顶级域名服务器dns.net告诉本地域名服务器，下一次应查询的权限域名服务器dns.csdn.net的IP地址。本地域名服务器向权限域名服务器dns.cadn.net进行查询。权限域名服务器dns.csdn.net告诉本地域名服务器，所查询的主机www.csdn.net的IP地址。本地域名服务器最后把结果告诉主机。

3.浏览器与目标服务器建立TCP连接

主机浏览器通过DNS解析得到了目标服务器的IP地址后，与服务器建立TCP连接
TCP三次握手建立连接：浏览器所在的客户机向服务器发出连接请求报文(SYN标志为1)；客户机接收到确认报文后，再次向服务器发出报文(SYN,ACK标志位均为1)；客户机接收到确认报文后，再次向服务器发出报文，确认已接收到确认包问；此处客户机与服务器之间的TCP连接建立完成，开始通信
4.浏览器给web服务器发送一个HTTP请求

浏览器向主机发起一个HTTP-GET方法的请求。请求的方法包含访问的URL，也就是http://www.csdn.com/ ，KeepAlive，长连接，还有User-Agent用户浏览器操作系统信息，编码等。值得一提的是Accep-Econding的Cookies项。Accept-Ecnoding一般采用gzip，压缩之后传输html文件。Cookies如果是首次访问，会提示服务器建立用户缓存信息，如果不是，可以利用Cookies对应键值，找到相应缓存，缓存里面存放着用户名，密码和一些用户设置项

5.某些服务器会做永久重定向响应

对于大型网站存在多个主机站点，负载均衡或者导入流量，提高SEO排名。往往不会直接返回请求页面，而是重定向。返回的状态码不是200ok，而是301，302以3开头的重定向码，浏览器在获取了重定向响应后，在响应报文中Location项找到重定向地址，浏览器重新第一步访问即可。

重定向的作用：重定向是为了负载均衡或者导入流量，提高SEO排名。利用一个前端服务器接受请求，然后负载到不同的主机上，可以大大提高站点的业务并发处理能力，重定向也可将多个域名的访问，集中到一个站点；由于baidu.com，www.baidu.com会被搜索引擎认为是两个网站，造成每个的连接数都活减少从而降低排名，永久重定向会将两个地址关联起来，搜索引擎会认为是同一个网站，从而提高排名

6.浏览器跟踪重定向地址

当浏览器知道了重定向后最终的访问地址之后，重新发送一个http请求，发送内容同上。

7.服务器处理请求

服务器接收到获取请求，然后处理并返回一个响应

8.服务器发出一个HTML响应

返回状态码200 ok，表示服务器可以响应请求，返回报文，由于在报头中Content-type为“text/html”，浏览器以HTML形式呈现，而不是下载文件。

9.释放TCP连接

浏览器所在的主机向服务器发出连接释放报文，然后停止发送数据
服务器接收到释放连接报文后发出确认报文，然后将服务器上未传送完的数据发送完
服务器数据传输完毕后，向客户机发送连接释放报文
客户机接收到报文后，发出确认，然后等待一段时间后，释放TCP连接
10.浏览器显示页面

在浏览器没有完整接收全部HTML文档时，它就已经开始显示这个页面了，浏览器收到返回的数据包，根据浏览器的渲染机制对响应的数据进行渲染。渲染后的数据，进行相应的页面呈现和脚步的交互

11.浏览器发送获取嵌入在HTML中的其他内容

比如一些样式文件，图片url，js文件url等，浏览器会通过这些url重新发送请求，请求过程依然是HTML读取类似的过程，查询域名，发送请求，重定向等。不过这些静态文件是可以缓存到浏览器中的，有时访问这些文件不需要通过服务器，直接从缓存中取。某些网站也会使用第三方CDN进行托管这些静态文件。

## 3.6 状态码

1XX——响应中-临时状态码，表示请求已经接收

2XX——表明请求被正常处理了

1、200 OK：请求已正常处理。

2、204 No Content：请求处理成功，但没有任何资源可以返回给客户端，一般在只需要从客户端往服务器发送信息，而对客户端不需要发送新信息内容的情况下使用。

3、206 Partial Content：是对资源某一部分的请求，该状态码表示客户端进行了范围请求，而服务器成功执行了这部分的GET请求。响应报文中包含由Content-Range指定范围的实体内容。

3XX——表明浏览器需要执行某些特殊的处理以正确处理请求

4、301 Moved Permanently：资源的uri已更新，你也更新下你的书签引用吧。永久性重定向，请求的资源已经被分配了新的URI，以后应使用资源现在所指的URI。

5、302 Found：资源的URI已临时定位到其他位置了，姑且算你已经知道了这个情况了。临时性重定向。和301相似，但302代表的资源不是永久性移动，只是临时性性质的。换句话说，已移动的资源对应的URI将来还有可能发生改变。

6、303 See Other：资源的URI已更新，你是否能临时按新的URI访问。该状态码表示由于请求对应的资源存在着另一个URL，应使用GET方法定向获取请求的资源。303状态码和302状态码有着相同的功能，但303状态码明确表示客户端应当采用GET方法获取资源，这点与302状态码有区别。

当301,302,303响应状态码返回时，几乎所有的浏览器都会把POST改成GET，并删除请求报文内的主体，之后请求会自动再次发送。

7、304 Not Modified：资源已找到，但未符合条件请求。该状态码表示客户端发送附带条件的请求时（采用GET方法的请求报文中包含If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since中任一首部）服务端允许请求访问资源，但因发生请求未满足条件的情况后，直接返回304.。

8、307 Temporary Redirect：临时重定向。与302有相同的含义。

4XX——表明客户端是发生错误的原因所在。

9、400 Bad Request：服务器端无法理解客户端发送的请求，请求报文中可能存在语法错误。

10、401 Unauthorized：该状态码表示发送的请求需要有通过HTTP认证（BASIC认证，DIGEST认证）的认证信息。

11、403 Forbidden：不允许访问那个资源。该状态码表明对请求资源的访问被服务器拒绝了。（权限，未授权IP等）

12、404 Not Found：服务器上没有请求的资源。路径错误等。

5XX——服务器本身发生错误

13、500 Internal Server Error：貌似内部资源出故障了。该状态码表明服务器端在执行请求时发生了错误。也有可能是web应用存在bug或某些临时故障。

14、503 Service Unavailable：抱歉，我现在正在忙着。该状态码表明服务器暂时处于超负载或正在停机维护，现在无法处理请求。

## 3.7 http协议

### 3.7.1 请求数据格式

- 请求行：请求方式 资源路径 协议

- 请求头：key-value格式

host：请求的主机名

user-agent：浏览器版本，兼容处理

accept：浏览器能接受的资源类型

content-type：请求主体的数据数据类型

- 请求体：post特有，用来存放请求参数

### 3.7.2 响应数据格式

- 响应行：协议 状态码 描述
- 响应头：key-value格式
- 响应体

## 3.8 HTTP与HTTPS

### 3.8.1 HTTP 和 HTTPS 的基本概念

**HTTP**：超文本传输协议（HTTP，HyperText Transfer Protocol）是互联网上应用最为广泛的一种网络协议。设计 HTTP 最初的目的是为了提供一种发布和接收 HTML 页面的方法。它可以使浏览器更加高效。HTTP 协议是以明文方式发送信息的，如果黑客截取了 Web 浏览器和服务器之间的传输报文，就可以直接获得其中的信息。

**HTTP 原理**：

①  客户端的浏览器首先要通过网络与服务器建立连接，该连接是通过 TCP 来完成的，一般 TCP 连接的端口号是80。 建立连接后，客户机发送一个请求给服务器，请求方式的格式为：统一资源标识符（URI）、协议版本号，后边是 MIME 信息包括请求修饰符、客户机信息和许可内容。

②  服务器接到请求后，给予相应的响应信息，其格式为一个状态行，包括信息的协议版本号、一个成功或错误的代码，后边是 MIME 信息包括服务器信息、实体信息和可能的内容。

**HTTPS**：是以安全为目标的 HTTP 通道，是 HTTP 的安全版。HTTPS 的安全基础是 SSL。SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。SSL 协议可分为两层：SSL 记录协议（SSL Record Protocol），它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。SSL 握手协议（SSL Handshake Protocol），它建立在 SSL 记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。

​                                                       

**HTTPS 设计目标**：

(1) 数据保密性：保证数据内容在传输的过程中不会被第三方查看。就像快递员传递包裹一样，都进行了封装，别人无法获知里面装了什么  。

(2) 数据完整性：及时发现被第三方篡改的传输内容。就像快递员虽然不知道包裹里装了什么东西，但他有可能中途掉包，数据完整性就是指如果被掉包，我们能轻松发现并拒收 。

(3) 身份校验安全性：保证数据到达用户期望的目的地。就像我们邮寄包裹时，虽然是一个封装好的未掉包的包裹，但必须确定这个包裹不会送错地方，通过身份校验来确保送对了地方  。

### 3.8.2 HTTP 与 HTTPS  的区别

1、HTTPS  协议需要到 CA （Certificate Authority，证书颁发机构）申请证书，一般免费证书较少，因而需要一定费用。(以前的网易官网是http，而网易邮箱是 https 。)

2、HTTP 是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的 SSL 加密传输协议。

3、HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

4、HTTP 的连接很简单，是无状态的。HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。(无状态的意思是其数据包的发送、传输和接收都是相互独立的。无连接的意思是指通信双方都不长久的维持对方的任何信息。)

### 3.8.3 HTTPS 相对于 HTTP 的改进

**双向的身份认证**

客户端和服务端在传输数据之前，会通过基于X.509证书对双方进行身份认证 。具体过程如下：

客户端发起 SSL 握手消息给服务端要求连接。

服务端将证书发送给客户端。

客户端检查服务端证书，确认是否由自己信任的证书签发机构签发(客户端内置了所有受信任 CA 的证书)。 如果不是，将是否继续通讯的决定权交给用户选择 ( 注意，这里将是一个安全缺陷 )。如果检查无误或者用户选择继续，则客户端认可服务端的身份。

服务端要求客户端发送证书，并检查是否通过验证。失败则关闭连接，认证成功则从客户端证书中获得客户端的公钥，一般为 1024 位或者 2048 位。到此，服务器客户端双方的身份认证结束，双方确保身份都是真实可靠的。

注意：

(1) 采用 HTTPS 协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问。这套证书其实就是一对公钥和私钥。

(2) 互联网有太多的服务需要使用证书来验证身份，以至于客户端（操作系统或浏览器等）无法内置所有证书，需要通过服务端将证书发送给客户端。

(3) 客户端内置的是 CA 的根证书(Root Certificate)，HTTPS 协议中服务器会发送证书链（Certificate Chain）给客户端。

**数据传输的机密性**

客户端和服务端在开始传输数据之前，会协商传输过程需要使用的加密算法。 客户端发送协商请求给服务端, 其中包含自己支持的非对成加密的密钥交换算法 ( 一般是RSA)，数据签名摘要算法 ( 一般是SHA或者MD5) ，加密传输数据的对称加密算法 ( 一般是DES)，以及加密密钥的长度。 服务端接收到消息之后，选中安全性最高的算法，并将选中的算法发送给客户端，完成协商。客户端生成随机的字符串，通过协商好的非对称加密算法，使用服务端的公钥对该字符串进行加密，发送给服务端。 服务端接收到之后，使用自己的私钥解密得到该字符串。在随后的数据传输当中，使用这个字符串作为密钥进行对称加密。

**防止重放攻击**

SSL 使用序列号来保护通讯方免受报文重放攻击。这个序列号被加密后作为数据包的负载。在整个 SSL 握手中，都有一个唯一的随机数来标记 SSL 握手。 这样防止了攻击者嗅探整个登录过程，获取到加密的登录数据之后，不对数据进行解密，而直接重传登录数据包的攻击手法。

可以看到，鉴于电子商务等安全上的需求，HTTPS 对比 HTTP 协议，在安全方面已经取得了极大的增强。总结来说，HTTPS 的改进点在于创造性的使用了非对称加密算法，在不安全的网路上，安全的传输了用来进行非对称加密的密钥，综合利用了非对称加密的安全性和对称加密的快速性。

### 3.8.4 HTTPS 的优缺点

**优点**

1、使用 HTTPS 协议可认证用户和服务器，确保数据发送到正确的客户机和服务器。

2、HTTPS 协议是由SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，要比 HTTP 协议安全，可防止数据在传输过程中不被窃取、修改，确保数据的完整性。

3、HTTPS 是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。

**缺点（对比优点）**
1、HTTPS 协议握手阶段比较费时，会使页面的加载时间延长近。

2、HTTPS 连接缓存不如 HTTP 高效，会增加数据开销，甚至已有的安全措施也会因此而受到影响。

3、HTTPS 协议的安全是有范围的，在黑客攻击、拒绝服务攻击和服务器劫持等方面几乎起不到什么作用。

4、SSL 证书通常需要绑定 IP，不能在同一 IP 上绑定多个域名，IPv4 资源不可能支撑这个消耗。

5、成本增加。部署 HTTPS 后，因为 HTTPS 协议的工作要增加额外的计算资源消耗，例如 SSL 协议加密算法和 SSL 交互次数将占用一定的计算资源和服务器成本。

6、HTTPS 协议的加密范围也比较有限。最关键的，SSL 证书的信用链体系并不安全，特别是在某些国家可以控制 CA 根证书的情况下，中间人攻击一样可行。

### 3.8.5 HTTPS 的连接过程

① 客户端的浏览器向服务器发送请求，并传送客户端 SSL 协议的版本号，加密算法的种类，产生的随机数，以及其他服务器和客户端之间通讯所需要的各种信息。

② 服务器向客户端传送 SSL 协议的版本号，加密算法的种类，随机数以及其他相关信息，同时服务器还将向客户端传送自己的证书。

③ 客户端利用服务器传过来的信息验证服务器的合法性，服务器的合法性包括：证书是否过期，发行服务器证书的 CA 是否可靠，发行者证书的公钥能否正确解开服务器证书的 "发行者的数字签名"，服务器证书上的域名是否和服务器的实际域名相匹配。如果合法性验证没有通过，通讯将断开；如果合法性验证通过，将继续进行第四步。

④ 用户端随机产生一个用于通讯的 "对称密码"，然后用服务器的公钥（服务器的公钥从步骤②中的服务器的证书中获得）对其加密，然后将加密后的“预主密码”传给服务器。

⑤ 如果服务器要求客户的身份认证（在握手过程中为可选），用户可以建立一个随机数然后对其进行数据签名，将这个含有签名的随机数和客户自己的证书以及加密过的密钥一起传给服务器。

⑥ 如果服务器要求客户的身份认证，服务器必须检验客户证书和签名随机数的合法性，具体的合法性验证过程包括：客户的证书使用日期是否有效，为客户提供证书的 CA  是否可靠，发行 CA 的公钥能否正确解开客户证书的发行 CA 的数字签名，检查客户的证书是否在证书废止列表（CRL）中。检验如果没有通过，通讯立刻中断；如果验证通过，服务器将用自己的私钥解开加密的私钥，然后执行一系列步骤来产生主通讯密码（客户端也将通过同样的方法产生相同的主通讯密码）。

⑦ 服务器和客户端用相同的对称加密密钥，对称密钥用于 SSL 协议的安全数据通讯的加解密通讯。同时在 SSL 通讯过程中还要完成数据通讯的完整性，防止数据通讯中的任何变化。

⑧ 客户端向服务器端发出信息，指明后面的数据通讯将使用的步骤 ⑦ 中的主密码为对称密钥，同时通知服务器客户端的握手过程结束。

⑨ 服务器向客户端发出信息，指明后面的数据通讯将使用的步骤 ⑦ 中的主密码为对称密钥，同时通知客户端服务器端的握手过程结束。

⑩ SSL 的握手部分结束，SSL 安全通道的数据通讯开始，客户和服务器开始使用相同的对称密钥进行数据通讯，同时进行通讯完整性的检验。

上述的过程需要弄懂的核心思想
客户端解析证书

这部分工作是由客户端的 TLS 来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个对称加密密钥，然后用公钥对该密钥进行非对称加密。

传送加密信息

这部分传送的是用公钥加密后的对称加密密钥，目的就是让服务端得到这个密钥，以后客户端和服务端的通信就可以通过这个密钥来进行加密解密了。

服务端解密信息

服务端用非对称加密算法里的私钥解密后，得到了客户端传过来的对称加密算法的私钥，然后把之后传输的内容通过该值进行对称加密。

**为什么用非对称加密协商对称加密密钥**

对称加密的特点：对称密码体制中只有一种密钥，并且是非公开的。如果要解密就得让对方知道密钥，所以想要保证其安全性就要保证密钥的安全。

非对称加密的特点：算法强度复杂、安全性依赖于算法与密钥但是由于其算法复杂，而使得加密解密速度没有对称加密解密的速度快。非对称密钥体制有两种密钥，其中一个是公开的，这样就可以不需要像对称密码那样传输对方的密钥了，这样安全性就大了很多。

非对称加密公钥和私钥的使用方法：(1) 公钥加密私钥解密。(2) 私钥做数字签名，公钥验证。

补充：
SSL 提供服务
(1) 认证用户和服务器，确保数据发送到正确的客户机和服务器；

(2) 加密数据以防止数据中途被窃取；

(3) 维护数据的完整性，确保数据在传输过程中不被改变。

### 3.8.6 SSL 工作流程

服务器认证阶段：

(1) 客户端向服务器发送一个开始信息 "Hello" 以便开始一个新的会话连接；

(2) 服务器根据客户的信息确定是否需要生成新的主密钥，如需要则服务器在响应客户的 "Hello" 信息时将包含生成主密钥所需的信息；

(3) 客户根据收到的服务器响应信息，产生一个主密钥，并用服务器的公开密钥加密后传给服务器；

(4) 服务器回复该主密钥，并返回给客户一个用主密钥认证的信息，以此让客户认证服务器。

用户认证阶段：在此之前，服务器已经通过了客户认证，这一阶段主要完成对客户的认证。经认证的服务器发送一个提问给客户，客户则返回（数字）签名后的提问和其公开密钥，从而向服务器提供认证。

SSL 协议提供的安全通道有以下三个特性：

机密性：SSL 协议使用密钥加密通信数据。

可靠性：服务器和客户都会被认证，客户的认证是可选的。

完整性：SSL 协议会对传送的数据进行完整性检查。

服务器证书(server certificates)是 SSL 数字证书的一种形式，意指通过提交数字证书来证明您的身份或表明您有权访问在线服务。再者简单来说，通过使用服务器证书可为不同站点提供身份鉴定并保证该站点拥有高强度加密安全。是组成 Web 服务器的 SSL 安全功能的唯一的数字标识。通过相互信任的第三方组织获得，并为用户提供验证您 Web 站点身份的手段。服务器证书包含详细的身份验证信息，如服务器内容附属的组织、颁发证书的组织以及称为公开密钥的唯一的身份验证文件。

## 3.9 Tcp和Udp

1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接
2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保   证可靠交付
3、TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的
  UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）
4、每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信
5、TCP首部开销20字节;UDP的首部开销小，只有8个字节
6、TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道

## 3.10 TCP可靠传输

### 3.10.1 流量控制

如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，对发送方发送速率的控制，要让接收方来得及接收。

利用**滑动窗口机制**可以很方便地在TCP连接上实现对发送方的流量控制。

**1.1 如何控制？**
接收方每次收到数据包，可以在发送确定报文的时候，同时告诉发送方自己的缓存区还剩余多少是空闲的，我们也把缓存区的剩余大小称之为接收窗口大小，用变量win来表示接收窗口的大小。
发送方收到之后，便会调整自己的发送速率，也就是调整自己发送窗口的大小，当发送方收到接收窗口的大小为0时，发送方就会停止发送数据，防止出现大量丢包情况的发生。
**1.2 发送方何时再继续发送数据?**
当发送方收到接受窗口 win = 0 时，这时发送方停止发送报文，并且同时开启一个定时器（心跳包），每隔一段时间就发个测试报文去询问接收方，打听是否可以继续发送数据了，如果可以，接收方就告诉他此时接受窗口的大小；如果接受窗口大小还是为0，则发送方再次刷新启动定时器。
**1.3 注意点：**
由于TCP/IP支持全双工传输，因此通信的双方都拥有两个滑动窗口，一个用于接受数据，称之为接收窗口；一个用于发送数据，称之为拥塞窗口(即发送窗口)。指出接受窗口大小的通知我们称之为窗口通告。
在早期的TCP协议中，接受接受窗口的大小确实是固定的，不过随着网络的快速发展，固定大小的窗口太不灵活了，成为TCP性能瓶颈之一，也就是说，在现在的TCP协议中，接受窗口的大小是根据某种算法动态调整的。
接受窗口如果太小的话，显然是不行的，这会严重浪费链路利用率，增加丢包率。那是否越大越好呢？答否，当接收窗口达到某个值的时候，再增大的话也不怎么会减少丢包率的了，而且还会更加消耗内存。所以接收窗口的大小必须根据网络环境以及发送发的的拥塞窗口来动态调整。
接收方在发送确认报文的时候，会告诉发送发自己的接收窗口大小，而发送方的发送窗口会据此来设置自己的发送窗口，但这并不意味着他们就会相等。首先接收方把确认报文发出去的那一刻，就已经在一边处理堆在自己缓存区的数据了，所以一般情况下接收窗口 >= 发送窗口。

### 3.10.2 TCP拥塞控制

**2.1 拥塞控制的原理**
发送方维持一个拥塞窗口 cwnd ( congestion window )的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。

发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。

**2.2 慢开始算法**
当主机开始发送数据时，如果立即将大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是 先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。

通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理。


慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。

为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。慢开始门限ssthresh的用法如下：

当 cwnd < ssthresh 时，使用上述的慢开始算法。
当 cwnd > ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。
当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。拥塞避免
**2.3 拥塞避免**
让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。


无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送 方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。

这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。

**2.4 乘法减小和加法增大**
乘法减小：是指不论在慢开始阶段还是拥塞避免阶段，只要出现超时，就把慢开始门限减半，即设置为当前的拥塞窗口的一半（于此同时，执行慢开始算法）。当网络出现频繁拥塞时，ssthresh值就下降的很快，以大大将小注入到网络中的分组数。

加法增大：是指执行拥塞避免算法后是拥塞窗口缓慢增大，以防止网络过早出现拥塞。

**2.5 拥塞控制和流量控制的差别**
所谓拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能承受现有的网络负荷。

拥塞问题是一个全局性的问题,涉及到所有的主机、所有的路由器、以及与降低网络传输性能有关的所有因素。

流量控制往往指的是点对点通信量的控制，是个端到端的问题。流量控制所要做的就是控制发送端发送数据的速率，以便使接收端来得及接受。

### 3.10.3 TCP重传机制

**3.1 快重传**
快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时才进行捎带确认。

接收方收到了M1和M2后都分别发出了确认。现在假定接收方没有收到M3但接着收到了M4。

显然，接收方不能确认M4，因为M4是收到的失序报文段。根据 可靠传输原理，接收方可以什么都不做，也可以在适当时机发送一次对M2的确认。

但按照快重传算法的规定，接收方应及时发送对M2的重复确认，这样做可以让 发送方及早知道报文段M3没有到达接收方。发送方接着发送了M5和M6。接收方收到这两个报文后，也还要再次发出对M2的重复确认。这样，发送方共收到了 接收方的四个对M2的确认，其中后三个都是重复确认。

快重传算法还规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段M3，而不必 继续等待M3设置的重传计时器到期。

由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%。

**3.2 快恢复**
当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。
与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为 慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。

**3.3 超时重传机制**
死等M3，当发送方发现收不到M3的ack超时后，会重传M3。一旦接收方收到M3后，会ack 回M4——意味着M3和M4都收到了。

但是，这种方式会有比较严重的问题，那就是因为要死等M3，所以会导致M4和M5即便已经收到了，而发送方也完全不知道发生了什么事，因为没有收到Ack，所以，发送方可能会悲观地认为也丢了，所以有可能也会导致4和5的重传。

对此有两种选择：

一种是仅重传timeout的包。也就是第3份数据。
另一种是重传timeout后所有的数据，也就是第3，4，5这三份数据。
这两种方式有好也有不好。第一种会节省带宽，但是慢，第二种会快一点，但是会浪费带宽，也可能会有无用功。但总体来说都不好。因为都在等timeout，timeout可能会很长。

## 3.11 Cookie 和 Session

**一、session的概念及特点**
session概念:在计算机中，尤其是在网络应用中，称为“会话控制”。Session 对象存储特定用户会话所需的属性及配置信息。说白了session就是一种可以维持服务器端的数据存储技术。session主要有以下的这些特点：

session保存的位置是在服务端
session一般来说要配合cookie使用，如果用户浏览器禁用了cookie，那么只能使用URL重写来实现session的存储功能

单纯的使用session来存储用户回话信息，那么当用户量较多时，session文件数量会很多，会存在session查询慢的问题

本质上：session技术就是一种基于后端有别于数据库的临时存储技术

**二、为什么要使用session**
我们目前使用的互联网应用层协议基本上都是基于 HTTP 和 HTTPS 的，它们的本身是无状态的， 只负责请求和响应。 我告诉服务器我需要什么，服务器返回给我相应的资源。 如果没有额外处理的话， 服务器是不知道你是谁，更无法根据你是谁给你展现和你相关的内容了。

HTTP 协议一开始被设计成这样还是有一些历史原因的，当时的互联网多用于学术交流，只用于文章信息的展现之类的事情，远没有现在这么丰富多彩。所以在当时的背景下 HTTP 协议被设计成这样其实也是很符合它的场景的。但随着互联网应用越来越广泛，应用的形式也变得越来越多，我们的 Web 应用不只限于提供简单的信息展现了，还需要用户能够登录，可以在论坛发帖子，在购物网站买东西等等。 这就需要 HTTP 协议能够记录用户的状态。也就是我们现在熟悉的 Session 由来。

**三、session的工作原理**
用户第一次请求服务器时，服务器端会生成一个sessionid
服务器端将生成的sessionid返回给客户端，通过set-cookie
客户端收到sessionid会将它保存在cookie中，当客户端再次访问服务端时会带上这个sessionid
当服务端再次接收到来自客户端的请求时，会先去检查是否存在sessionid，不存在就新建一个sessionid重复1,2的流程，如果存在就去遍历服务端的session文件，找到与这个sessionid相对应的文件，文件中的键值便是sessionid，值为当前用户的一些信息
此后的请求都会交换这个 Session ID，进行有状态的会话。

**四、session与cookies区别**
1、数据存放位置不同：

cookie数据存放在客户的浏览器上，session数据放在服务器上。

2、安全程度不同：

cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗,考虑到安全应当使用session。

3、性能使用程度不同：

session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能,考虑到减轻服务器性能方面，应当使用cookie。

4、数据存储大小不同：

单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie，而session则存储与服务端，浏览器对其没有限制。

5、会话机制不同

session会话机制：session会话机制是一种服务器端机制，它使用类似于哈希表（可能还有哈希表）的结构来保存信息。
cookies会话机制：cookie是服务器存储在本地计算机上的小块文本，并随每个请求发送到同一服务器。 Web服务器使用HTTP标头将cookie发送到客户端。在客户端终端，浏览器解析cookie并将其保存为本地文件，该文件自动将来自同一服务器的任何请求绑定到这些cookie。

**五、session的生命周期**
Session何时生效：
Sessinon在用户访问第一次访问服务器时创建，需要注意只有访问JSP、Servlet等程序时才会创建Session，只访问HTML、IMAGE等静态资源并不会创建Session,可调用request.getSession(true)强制生成Session。

Session何时失效：
1.服务器会把长时间没有活动的Session从服务器内存中清除，此时Session便失效。Tomcat中Session的默认失效时间为20分钟。从session不活动的时候开始计算，如果session一直活动，session就总不会过期。从该Session未被访问,开始计时; 一旦Session被访问,计时清0;

2.调用Session的invalidate方法

HttpSession session = request.getSession();
session.invalidate();//注销该request的所有session
3.设置session的失效时间
4.关闭浏览器，session就会失效

**六、session的性能瓶颈**
另外一个要聊聊的就是 Session 数据的存储。 通常情况下，如果你不明确的设置， 大多数 Web 框架会把 Session 数据存放到内存中。如果你的 Web 应用用户量不大的话，这也不成问题。 但如果你的用户数比较大的话，就可能发生一个事情 — 内存不够用了。

这很正常，内存容量是非常宝贵的，假设每个用户的 Session 数据是 100K， 1万个用户就会大概占用 1G 的存储空间，如果你的 Session 数据清理机制也恰巧比较慢的话，内存非常容易被占满。这就需要你在设计比较大并发量的站点时，要考虑 Session 的存储方式，比如把它们保存到硬盘文件系统中，或者数据库中。 所以你在开发一个 Web 应用的时候，如果你的用户量很大，你需要有这个意识。另外 Session 放到内存中还有一个弊端，如果你的 Web 服务器发生重启，那么所有的 Session 状态都会被情况，会在一定程度上影响用户体验。

**一、Cookie的概述**
Cookie是客户端的技术(默认把Cookie保存在每个用户的浏览器上)
程序把每个用户的数据以cookie的形式写给用户各自的浏览器
当用户使用浏览器再去访问服务器中的web资源时,就会带着各自的数据去
**二、Cookie的原理**
Cookie基于客户端的技术,Cookie的对象是服务器端创建的,默认把Cookie保存在客户端浏览器上
Cookie基于http的协议,默认有两个(set-cookie是响应头,服务器端到客户端 cookie是请求头,客户端到服务器端)
Cookie可以在客户端与服务器端进数据的传递

### 3.11.1 区别与联系

一、cookie 和session 的区别：
1、cookie数据存放在客户的浏览器上，session数据放在服务器上。
2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗,考虑到安全应当使用session。
3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能,考虑到减轻服务器性能方面，应当使用COOKIE。

4、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。

二、cookie 和session 的联系：
session和cookie之间是通过C O O K I E [ ′ P H P S E S S I D ′ ] 来联系的，通过_COOKIE[‘PHPSESSID’]可以知道session的id，从而获取到其他的信息

## 3.12 进程和线程

**什么是进程**

先给一个定义：进程是一个具有一定独立功能的程序在一个数据集合上依次动态执行的过程。进程是一个正在执行的程序的实例，包括程序计数器、寄存器和程序变量的当前值。

**进程有哪些特征？**

进程依赖于程序运行而存在，进程是动态的，程序是静态的；
进程是操作系统进行资源分配和调度的一个独立单位（CPU除外，线程是处理器任务调度和执行的基本单位）；
每个进程拥有独立的地址空间，地址空间包括代码区、数据区和堆栈区，进程之间的地址空间是隔离的，互不影响。
**什么是线程？**

进程的创建、销毁与切换存在着较大的时空开销，因此人们急需一种轻型的进程技术来减少开销。在80年代，线程的概念开始出现，线程被设计成进程的一个执行路径，同一个进程中的线程共享进程的资源，因此系统对线程的调度所需的成本远远小于进程。

**进程与线程的区别总结：**

本质区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。

包含关系：一个进程至少有一个线程，线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。

资源开销：每个进程都有独立的地址空间，进程之间的切换会有较大的开销；线程可以看做轻量级的进程，同一个进程内的线程共享进程的地址空间，每个线程都有自己独立的运行栈和程序计数器，线程之间切换的开销小。

影响关系：一个进程崩溃后，在保护模式下其他进程不会被影响，但是一个线程崩溃可能导致整个进程被操作系统杀掉，所以多进程要比多线程健壮。

## 3.13 进程间通信方式

前提知识：每个进程都有自己的用户空间，而内核空间是每个进程共享的。因此进程之间想要进行通信，就需要通过内核来实现。

**管道：**

管道是最简单，效率最差的一种通信方式。

管道本质上就是内核中的一个缓存，当进程创建一个管道后，Linux会返回两个文件描述符，一个是写入端的描述符，一个是输出端的描述符，可以通过这两个描述符往管道写入或者读取数据。

如果想要实现两个进程通过管道来通信，则需要让创建管道的进程fork子进程，这样子进程们就拥有了父进程的文件描述符，这样子进程之间也就有了对同一管道的操作。

缺点：

半双工通信，一条管道只能一个进程写，一个进程读。
一个进程写完后，另一个进程才能读，反之同理。
**消息队列：**

管道的通信方式效率是低下的，不适合进程间频繁的交换数据。这个问题，消息队列的通信方式就可以解决。A进程往消息队列写入数据后就可以正常返回，B进程需要时再去读取就可以了，效率比较高。

而且，数据会被分为一个一个的数据单元，称为消息体，消息发送方和接收方约定好消息体的数据类型，不像管道是无格式的字节流类型，这样的好处是可以边发送边接收，而不需要等待完整的数据。

但是也有缺点，每个消息体有一个最大长度的限制，并且队列所包含消息体的总长度也是有上限的，这是其中一个不足之处。

另一个缺点是消息队列通信过程中存在用户态和内核态之间的数据拷贝问题。进程往消息队列写入数据时，会发送用户态拷贝数据到内核态的过程，同理读取数据时会发生从内核态到用户态拷贝数据的过程。

**共享内存：**

共享内存解决了消息队列存在的内核态和用户态之间数据拷贝的问题。

现代操作系统对于内存管理采用的是虚拟内存技术，也就是说每个进程都有自己的虚拟内存空间，虚拟内存映射到真实的物理内存。共享内存的机制就是，不同的进程拿出一块虚拟内存空间，映射到相同的物理内存空间。这样一个进程写入的东西，另一个进程马上就能够看到，不需要进行拷贝。

（这里的物理内存貌似不是内核空间的内存？）

**信号量：**

当使用共享内存的通信方式，如果有多个进程同时往共享内存写入数据，有可能先写的进程的内容被其他进程覆盖了。

因此需要一种保护机制，信号量本质上是一个整型的计数器，用于实现进程间的互斥和同步。

信号量代表着资源的数量，操作信号量的方式有两种：

P操作：这个操作会将信号量减一，相减后信号量如果小于0，则表示资源已经被占用了，进程需要阻塞等待；如果大于等于0，则说明还有资源可用，进程可以正常执行。
V操作：这个操作会将信号量加一，相加后信号量如果小于等于0，则表明当前有进程阻塞，于是会将该进程唤醒；如果大于0，则表示当前没有阻塞的进程。
（1）信号量实现互斥：

信号量初始化为1

进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。
若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。
直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。
（2）信号量实现同步：

由于多线程下各线程的执行顺序是无法预料的，有些时候我们希望多个线程之间能够密切合作，这时候就需要考虑线程的同步问题。

信号量初始化为0

如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待；
接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；
最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。
**信号：**

在Linux中，为了响应各种事件，提供了几十种信号，可以通过kill -l命令查看。

如果是运行在shell终端的进程，可以通过键盘组合键来给进程发送信号，例如使用Ctrl+C产生SIGINT信号，表示终止进程。

如果是运行在后台的进程，可以通过命令来给进程发送信号，例如使用kill -9 PID产生SIGKILL信号，表示立即结束进程。

**Socket：**

前面提到的管道，消息队列，共享内存，信号量和信号都是在同一台主机上进行进程间通信，如果想要跨网络和不同主机上的进程进行通信，则需要用到socket。

实际上，Socket不仅可以跨网络和不同主机进行进程间通信，还可以在同一主机进行进程间通信。

Socket是操作系统提供给程序员操作网络的接口，根据底层不同的实现方式，通信方式也不同。
针对TCP的Socket通信：

服务端和客户端初始化Socket，得到文件描述符
服务端调用bind，绑定IP和端口
服务端调用listen，进行监听
服务端调用accept，等待客户端连接
客户端调用connect，向服务端发起连接请求。（TCP三次握手）
服务端调用accept返回用于传输的Socket的文件描述符（和第一点得到的Socket不同）
客户端使用write写入数据，服务端调用read读取数据
客户端断开连接时会调用close，服务端也会调用close（TCP四次挥手）
这里要注意的是，调用accept，连接成功得到的Socket是用来传输数据的，而第一次初始化Socket是用来监听的，是两个不同作用的Socket。

# 4.  Java

## 4.1 基础

### 4.1.1反射机制

#### 4.1.1.1 反射四大功能

- 在运行时获知任意一个对象的所属类 class.getClass  class.isInstance
- 在运行时构造任意一个类的对象 class.newInstance
- 在运行时获知任意一个类所具有的成员变量和方法 class.getField
- 在运行时调用任意一个对象的方法和属性 class.getMethod     invoke

这种动态获取信息，动态调用对象的方法的功能就称为的反射机制。

#### 4.1.1.2 反射的原理

首先JVM会将代码编译成一个.class的字节码文件，然后被类加载器（ClassLoader）加载进JVM的内存中，同时会创建这个类的Class对象存到堆中。JVM在创建这个类对象之前，会先检查类是否加载，寻找类对应的Class对象，若加载好，则为其分配内存，然后进行初始化操作。

类加载完成之后，堆内存的方法区就产生了一个Class对象，并且包含了这个类的完整结构信息，我们可以通过这个Class对象看到类的结构，形象地称为反射。

#### 4.1.1.3 反射的优缺点

优点：比较灵活，能够在运行时动态获取类的实例。

缺点：性能慢，破坏了封装性。

#### 4.1.1.4 反射的实际应用

1. 动态代理机制
2. 使用JDBC连接数据库
3. Spring框架中的动态代理

### 4.1.2 类加载机制

加载→验证→准备→解析→初始化→使用→卸载

加载：读取Class文件，将其转化为某种静态数据结构存储在方法区中，并在堆中生成一个便于用户调用的java.lang.class类型的对象的过程。

验证：文件格式验证（加载阶段） 元数据验证 字节码验证 符号引用验证（解析阶段）

准备：静态变量赋初始值

解析：符号引用替换为直接引用

初始化：静态变量init

### 4.1.3 类加载器

#### 4.1.3.1 类加载器分类

Bootstrap ClassLoader 

Extension ClassLoader    java_home /lib/ext

Application ClassLoader     classpath

User ClassLoader     任意来源

#### 4.1.3.2 双亲委派模型

需求：默认情况下，一个限定名的类指挥被一个类加载器加载并解析使用，这样在程序中，他就是唯一的，不会产生歧义。

检查是否已经被加载过，没有的话，交给父亲加载。

### 4.1.4 BIO，NIO和AIO

BIO：同步并阻塞，服务实现模式为一个连接对应一个线程，即客户端发送一个连接，服务端要有一个线程来处理。如果连接多了，线程数量不够，就只能等待，即会发生阻塞。

NIO：同步非阻塞，服务实现模式是一个线程可以处理多个连接，即客户端发送的连接都会注册到多路复用器上，然后进行轮询连接，有I/O请求就处理

AIO：异步非阻塞，引入了异步通道，采用的是proactor模式，特点是：有效的请求才启动线程，先有操作系统完成在通知服务端

**应用场景：**

BIO：适用连接数目比较小且固定的架构，对服务器要求比较高，并发局限于应用中

NIO：适用连接数目多且连接比较短的架构，如：聊天服务器，弹幕系统等，编程比较复杂

AIO：适用连接数目多且连接长的架构，如相册服务器

**BIO和NIO的区别**

1.BIO主要是以I/O流的形式处理数据；NIO以I/O块（buffer）的形式处理数据，效率：块>流

2.BIO是阻塞的，NIO是非阻塞的

3.BIO主要是以字节流和字符流操作，NIO是基于channel（通道）、buffer（缓冲区）操作的；selector（选择器）是用来监听channel的

4.BIO是单向的，要么是输入流要么是输出流，NIO是双向的，可以从channel往buffer读写数据，同时buffer也可以向channel读写数据

### 4.1.5 final 关键字

final关键字可以修饰类、成员变量、方法、以及方法中的局部变量。

1、final修饰类
  可以使用final将类声明为final类。final类不能被继承，即不能有子类。有时候是出于一些安全性的考虑，将一些类修饰为final类。例如，Java在java.lang包中提供的String类对于编译器和解释器的正常运行有着很重要的作用，Java不允许用户程序扩展String类，为此，Java将它修饰为final类。

2、final修饰方法
  如果用final修饰父类中的一个方法，那么这个方法不允许子类重写，也就是说，不允许子类隐藏可以继承的final方法（老老实实继承，不做任何篡改）。

3、final修饰变量
  如果成员变量或局部变量被修饰为final，那他就是常量。由于常量在运行期间不允许再发生变化，所以常量在声明时没有默认值，这就要求程序在声明常量时指定该常量的值。
4、final修饰的对象
  final修饰的对象引用不可变，内容可变。

### 4.1.6 引用类型

**1．强引用（StrongReference）**

以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。如果一个对象具有强引用，那就类似于**必不可少的生活用品**，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。

**2．软引用（SoftReference）**

如果一个对象只具有软引用，那就类似于**可有可无的生活用品**。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。

软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA 虚拟机就会把这个软引用加入到与之关联的引用队列中。

**3．弱引用（WeakReference）**

如果一个对象只具有弱引用，那就类似于**可有可无的生活用品**。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。

弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java 虚拟机就会把这个弱引用加入到与之关联的引用队列中。

**4．虚引用（PhantomReference）**

"虚引用"顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。

**虚引用主要用来跟踪对象被垃圾回收的活动**。

**虚引用与软引用和弱引用的一个区别在于：** 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。

## 4.2 JVM

### 4.2.1 JVM调优

标准参数 x参数 xx参数

标准参数一般是用来查看一些信息，比如JVM的版本号

x参数 xx参数用来设置JVM内存的一些参数 xx稳定性更差一点

xms 用来内存的初始大小 s代表初始值 以M为单位 默认物理内存的1/64

xmx 用来配置最大的堆内存 与xms设置相同，避免JVM的内存扩展

xmn 用来设置新生代的大小 默认为对空间的1/3或1/4

xss 设置线程虚拟机栈的大小

xx 设置堆内存新生代和老年代的比例 设置new对象的一个阈值，超过直接进入老年代 设置对象存活的年龄 设置GC日志是否打开+

### 4.2.2 内存区域

线程私有的：程序计数器、虚拟机栈、本地方法栈

线程共享的：堆、方法区、直接内存

![image-20230326230417276](F:\keep\img\image-20230326230417276.png)

java源代码不能被虚拟机执行，通过javac命令编译成javaclass字节码文件

执行java命令时，就会创建java虚拟机

①首先创建了一个main主线程，作为入口执行主方法。主线程存放在虚拟机栈中。

②虚拟机发现没见过的类，触发类加载机制。将类的所有原始信息加载到方法区，包括类的名字，继承关系，成员变量，继承的其它类的信息，类的方法代码。

③创建对象存放到堆内存

④局部变量和方法参数占用的是线程的栈内存。普通方法存储在虚拟机栈，本地方法存储在本地方法栈。

⑤线程不会一直占用系统资源，切换回来后根据程序计数器判断从哪行继续执行。

⑥当对象不使用时，内存不足触发垃圾回收进行回收。

⑦使用解释器将字节码翻译成机器码供CPU执行，解释器对同一行代码会反复执行。对于热点代码，使用即时编译器发现热点代码，翻译成机器代码缓存起来，提高执行效率。热点探测方式：采样热点猜测和计数器热点探测。

#### 4.2.2.1 程序计数器

程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。

另外，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。

从上面的介绍中我们知道了程序计数器主要有两个作用：

- 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。
- 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。

⚠️ 注意 ：程序计数器是唯一一个不会出现 `OutOfMemoryError` 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。

#### 4.2.2.2 Java虚拟机栈

与程序计数器一样，Java 虚拟机栈（后文简称栈）也是线程私有的，它的生命周期和线程相同，随着线程的创建而创建，随着线程的死亡而死亡。

栈绝对算的上是 JVM 运行时数据区域的一个核心，除了一些 Native 方法调用是通过本地方法栈实现的(后面会提到)，其他所有的 Java 方法调用都是通过栈来实现的（也需要和其他运行时数据区域比如程序计数器配合）。

方法调用的数据需要通过栈进行传递，每一次方法调用都会有一个对应的栈帧被压入栈中，每一个方法调用结束后，都会有一个栈帧被弹出。

栈由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法返回地址。和数据结构上的栈类似，两者都是先进后出的数据结构，只支持出栈和入栈两种操作。

#### 4.2.2.3 本地方法栈

和虚拟机栈所发挥的作用非常相似，区别是： **虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。** 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。

本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。

方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 `StackOverFlowError` 和 `OutOfMemoryError` 两种错误。

#### 4.2.2.4 堆

java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。**此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。**

Java 堆是垃圾收集器管理的主要区域，因此也被称作 **GC 堆（Garbage Collected Heap）**。从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代；再细致一点有：Eden、Survivor、Old 等空间。进一步划分的目的是更好地回收内存，或者更快地分配内存。

#### 4.2.2.5 方法区

方法区属于是 JVM 运行时数据区域的一块逻辑区域，是各个线程共享的内存区域。

当虚拟机要使用一个类时，它需要读取并解析 Class 文件获取相关信息，再将信息存入到方法区。方法区会存储已被虚拟机加载的 **类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据**。

**方法区和永久代以及元空间是什么关系呢？** 方法区和永久代以及元空间的关系很像 Java 中接口和类的关系，类实现了接口，这里的类就可以看作是永久代和元空间，接口可以看作是方法区，也就是说永久代以及元空间是 HotSpot 虚拟机对虚拟机规范中方法区的两种实现方式。并且，永久代是 JDK 1.8 之前的方法区实现，JDK 1.8 及以后方法区的实现变成了元空间。

#### 4.2.2.6 运行时常量池

Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有用于存放编译期生成的各种字面量（Literal）和符号引用（Symbolic Reference）的 **常量池表(Constant Pool Table)** 。

字面量是源代码中的固定值的表示法，即通过字面我们就能知道其值的含义。字面量包括整数、浮点数和字符串字面量，符号引用包括类符号引用、字段符号引用、方法符号引用和接口方法符号引用。

常量池表会在类加载后存放到方法区的运行时常量池中。

运行时常量池的功能类似于传统编程语言的符号表，尽管它包含了比典型符号表更广泛的数据。

既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 `OutOfMemoryError` 错误。

#### 4.2.2.7 字符串常量池

**字符串常量池** 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。

JDK1.7 之前，字符串常量池存放在永久代。JDK1.7 字符串常量池和静态变量从永久代移动了 Java 堆中。

**JDK 1.7 为什么要将字符串常量池移动到堆中？**

主要是因为永久代（方法区实现）的 GC 回收效率太低，只有在整堆收集 (Full GC)的时候才会被执行 GC。Java 程序中通常会有大量的被创建的字符串等待回收，将字符串常量池放到堆中，能够更高效及时地回收字符串内存。

#### 4.2.2.8 直接内存

直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 错误出现。

JDK1.4 中新加入的 **NIO(New Input/Output) 类**，引入了一种基于**通道（Channel）\**与\**缓存区（Buffer）\**的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为\**避免了在 Java 堆和 Native 堆之间来回复制数据**。

本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。

#### 4.2.2.9 内存溢出

除了程序计数器都会出现内存溢出

- 出现OutOfMemoryError的情况

堆内存耗尽——对象越来越多，又一直在使用，不能被垃圾回收

方法区内存耗尽——加载的类越来越多，很多框架都会产生新类

虚拟机栈累积——每个线程最多占用1M，线程数越来越多

- 出现StackOverflowError的情况

虚拟机内部——方法调用次数过多

#### 4.2.2.10 方法区与永久代、元空间之间的关系



### 4.2.3 对象的创建

#### Step1:类加载检查

虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。

#### Step2:分配内存

在**类加载检查**通过后，接下来虚拟机将为新生对象**分配内存**。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。**分配方式**有 **“指针碰撞”** 和 **“空闲列表”** 两种，**选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定**。

**内存分配的两种方式** （补充内容，需要掌握）：

- 指针碰撞 ：
  - 适用场合 ：堆内存规整（即没有内存碎片）的情况下。
  - 原理 ：用过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个分界指针，只需要向着没用过的内存方向将该指针移动对象内存大小位置即可。
  - 使用该分配方式的 GC 收集器：Serial, ParNew
- 空闲列表 ：
  - 适用场合 ： 堆内存不规整的情况下。
  - 原理 ：虚拟机会维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例，最后更新列表记录。
  - 使用该分配方式的 GC 收集器：CMS

选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是"标记-清除"，还是"标记-整理"（也称作"标记-压缩"），值得注意的是，复制算法内存也是规整的。

**内存分配并发问题（补充内容，需要掌握）**

在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：

- **CAS+失败重试：** CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。**虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。**
- **TLAB：** 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配

#### Step3:初始化零值

内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。

#### Step4:设置对象头

初始化零值完成之后，**虚拟机要对对象进行必要的设置**，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 **这些信息存放在对象头中。** 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。

#### Step5:执行 init 方法

在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，`<init>` 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 `<init>` 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。

### 4.2.4 对象定位

建立对象就是为了使用对象，我们的 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有：**使用句柄**、**直接指针**。

如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据各自的具体地址信息。

如果使用直接指针访问，reference 中存储的直接就是对象的地址。

这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。

### 4.2.5 垃圾回收

#### 4.2.5.1 内存分配

**对象优先在 Eden 区分配**

当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC。GC 期间虚拟机又发现 `allocation1` 无法存入 Survivor 空间，所以只好通过 **分配担保机制** 把新生代的对象提前转移到老年代中去，老年代上的空间足够存放 `allocation1`，所以不会出现 Full GC。执行 Minor GC 后，后面分配的对象如果能够存在 Eden 区的话，还是会在 Eden 区分配内存。

**大对象直接进入老年代**

大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。

大对象直接进入老年代主要是为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。

**长期存活的对象将进入老年代**

既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。

大部分情况，对象都会首先在 Eden 区域分配。如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间（s0 或者 s1）中，并将对象年龄设为 1(Eden 区->Survivor 区后对象的初始年龄变为 1)。

对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 `-XX:MaxTenuringThreshold` 来设置。

#### 4.2.5.2 可达性分析

这个算法的基本思想就是通过一系列的称为 **“GC Roots”** 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的，需要被回收。

**哪些对象可以作为 GC Roots 呢？**

- 虚拟机栈(栈帧中的本地变量表)中引用的对象
- 本地方法栈(Native 方法)中引用的对象
- 方法区中类静态属性引用的对象
- 方法区中常量引用的对象
- 所有被同步锁持有的对象

**对象可以被回收，就代表一定会被回收吗？**

即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 `finalize` 方法。当对象没有覆盖 `finalize` 方法，或 `finalize` 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。

被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。

#### 4.2.5.3 垃圾收集算法

##### 标记-清除算法

该算法分为“标记”和“清除”阶段：首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题：

##### 标记-复制算法

为了解决效率问题，“标记-复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。

##### 标记-整理算法

根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。

##### 分代收集算法

当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。

**比如在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。**

#### 4.2.5.4 垃圾收集器

#####  Serial 收集器

Serial（串行）收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 **“单线程”** 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ **"Stop The World"** ），直到它收集结束。

**新生代采用标记-复制算法，老年代采用标记-整理算法。**

虚拟机的设计者们当然知道 Stop The World 带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。

但是 Serial 收集器有没有优于其他垃圾收集器的地方呢？当然有，它**简单而高效（与其他收集器的单线程相比）**。Serial 收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial 收集器对于运行在 Client 模式下的虚拟机来说是个不错的选择。

##### ParNew 收集器

**ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。**

**新生代采用标记-复制算法，老年代采用标记-整理算法。**

它是许多运行在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器（真正意义上的并发收集器，后面会介绍到）配合工作。

##### Parallel Scavenge 收集器

Parallel Scavenge 收集器也是使用标记-复制算法的多线程收集器，它看上去几乎和 ParNew 都一样。 **那么它有什么特别之处呢？**

**Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。** Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解，手工优化存在困难的时候，使用 Parallel Scavenge 收集器配合自适应调节策略，把内存管理优化交给虚拟机去完成也是一个不错的选择。

**新生代采用标记-复制算法，老年代采用标记-整理算法。**

**这是 JDK1.8 默认收集器**

##### CMS 收集器

**CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。**

**CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。**

从名字中的**Mark Sweep**这两个词可以看出，CMS 收集器是一种 **“标记-清除”算法**实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：

- **初始标记：** 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；
- **并发标记：** 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。
- **重新标记：** 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短
- **并发清除：** 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。

从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：**并发收集、低停顿**。但是它有下面三个明显的缺点：

- **对 CPU 资源敏感；**
- **无法处理浮动垃圾；**
- **它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。**

##### G1 收集器

**G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.**

被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备以下特点：

- **并行与并发**：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。
- **分代收集**：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。
- **空间整合**：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。
- **可预测的停顿**：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。

G1 收集器的运作大致分为以下几个步骤：

- **初始标记**
- **并发标记**
- **最终标记**
- **筛选回收**

**G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)** 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。

## 4.3 并发编程

### 4.3.1 并发三大特性

原子性是指在一个操作中cpu不可以在中途暂停再调度，即不被中断操作，要不全部执行完成，要不都不执行。

可见性是指当多线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

有序性是指在进行代码编译时，对于那些改变顺序之后不会对最终结果造成影响的代码，虚拟机不一定会按照我们写的代码执行顺序来执行，有可能将他们重排序。

### 4.3.2 对线程安全的理解

当多个线程访问同一个对象时，如果不用进行额外的同步控制或其他协调工作，调用这个对象的香味都可以获得正确的结果，就称为时线程安全的。

### 4.3.3 ThreadLocal

#### 4.3.3.1 底层原理

1. ThreadLocal是Java中所提供的线程本地存储机制，可以利用该机制将数据缓存在某个线程内部，该线程可以在任意时刻、任意方法中获取缓存的数据
2. ThreadLocal底层是通过ThreadLocalMap来实现的，每个Thread对象中都存在一个ThreadLocalMap，Map的key为ThreadLocal对象，Map的value为需要缓存的值
3. 如果在线程池中使用ThreadLocal会造成内存泄漏，在ThreadLocal对象使用完之后，应该要把设置的key，value，也就是Entry对象回收，但线程池中的线程不会回收，线程对象是通过强引用指向ThreadLocalMap，ThreadLocalMap也是通过强引用指向Entry对象，线程不被回收，Entry对象也就不会被回收，从而出现内存泄漏。

#### 4.3.3.2 使用场景

1. 对象跨层传递，避免多次传递
2. 线程间数据隔离
3. 进行事务操作
4. 数据库连接，Session会话管理

#### 4.3.3.3 内存泄漏

内存泄漏：不会被使用的对象占用内存不能额被回收，就是内存泄露。

每个Thread维护一个ThreadLocalMap，key为使用弱引用ThreadLocal实例，value是值。

线程不结束，value就不会消失，ThreadLocal没了，key为null。

避免：使用完调用remove方法

ThreadLocal变量定义为private static，这样就一直存在ThreadLocal的强引用，也就能保证任何时候通过ThreadLocal的弱引用访问到Entry的value值，进而清除掉。

### 4.3.4 线程的生命周期

创建 就绪 运行 阻塞 死亡

等待阻塞：调用wait方法，线程会释放占用的所有资源，JVM会把线程放入等待池中。进入这个状态后，不能自动唤醒，必须依靠其他线程调用notify方法或notifyall方法才能唤醒。

同步阻塞：运行的线程获取对象的同步锁时，锁被占用，线程会被放入锁池中。

其他阻塞：运行的线程执行sleep或join方法，或io请求时，转为阻塞状态，当结束时，重新转入就绪状态。

#### 4.3.4.1 终止线程的方式

**正常运行结束** 

程序运行结束，线程自动结束。

**使用退出标志退出线程**

一般 run()方法执行完，线程就会正常结束，然而，常常有些线程是伺服线程。它们需要长时间的运行，只有在外部某些条件满足的情况

下，才能关闭这些线程。使用一个变量来控制循环，例如：最直接的方法就是设一个 boolean 类型的标志，并通过设置这个标志为 true 或false 来控制 while循环是否退出，

**Interrupt** **方法结束线程** 

使用 interrupt()方法来中断线程有两种情况： 

1.线程处于阻塞状态： 

如使用了 sleep,同步锁的 wait,socket 中的 receiver,accept 等方法时，会使线程处于阻塞状态。当调用线程的interrupt()方法时，会抛出 InterruptException 异常。阻塞中的那个方法抛出这个异常，通过代码捕获该异常，然后 break 跳出循环状态，从而让我们有机会结束这个线程的执行。 通常很多人认为只要调用 interrupt 方法线程就会结束，实际上是错的， 一定要先捕获InterruptedException 异常之后通过 break 来跳出循环，才能正常结束 run 方法。

2.线程未处于阻塞状态： 

使用 isInterrupted()判断线程的中断标志来退出循环。当使用interrupt()方法时，中断标志就会置 true，和使用自定义的标志来控制循环是一样的道理。 

**stop** **方法终止线程（线程不安全）** 

程序中可以直接使用 thread.stop()来强行终止线程，但是 stop 方法是很危险的，就象突然关闭计算机电源，而不是按正常程序关机一样，可能会产生不可预料的结果，不安全主要是：thread.stop()调用之后，创建子线程的线程就会抛出 ThreadDeatherror 的错误，并且会释放子线程所持有的所有锁。一般任何进行加锁的代码块，都是为了保护数据的一致性，如果在调用thread.stop()后导致了该线程所持有的所有锁的突然释放(不可控制)，那么被保护数据就有可能呈现不一致性，其他线程在使用这些被破坏的数据时，有可能导致一些很奇怪的应用程序错误。因此，并不推荐使用 stop 方法来终止线程。 

#### 4.3.4.2 JAVA 后台线程

1. 定义：守护线程--也称“服务线程”， 他是后台线程， 它有一个特性，即为用户线程 提供 公共服务， 在没有用户线程可服务时会自动离开。

2. 优先级：守护线程的优先级比较低，用于为系统中的其它对象和线程提供服务。

3. 设置：通过 setDaemon(true)来设置线程为“守护线程”；将一个用户线程设置为守护线程的方式是在 线程对象创建 之前 用线程对象的setDaemon 方法。

4. 在 Daemon 线程中产生的新线程也是 Daemon 的。

5. 线程则是 JVM 级别的，以 Tomcat 为例，如果你在 Web 应用中启动一个线程，这个线程的生命周期并不会和 Web 应用程序保持同步。也就是说，即使你停止了 Web 应用，这个线程依旧是活跃的。

6. example: 垃圾回收线程就是一个经典的守护线程，当我们的程序中不再有任何运行的Thread,程序就不会再产生垃圾，垃圾回收器也就无事可做， 所以当垃圾回收线程是 JVM 上仅剩的线程时，垃圾回收线程会自动离开。它始终在低级别的状态中运行，用于实时监控和管理系统中的可回收资源。

7. 生命周期：守护进程（Daemon）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。也就是说守护线程不依赖于终端，但是依赖于系统，与系统“同生共死”。当 JVM 中所有的线程都是守护线程的时候， JVM 就可以退出了；如果还有一个或以上的非守护线程则 JVM 不会退出 

### 4.3.5 线程池

#### 4.3.5.1 底层工作原理

1. 如果线程池中的线程数量 < 核心线程数，即使线程池中的线程都空闲，也要新建线程。
2. 如果线程池中的线程数量 = 核心线程数，但是缓冲队列未满，当如缓冲队列中。
3. 如果线程池中的线程数量 >= 核心线程数，缓冲队列满了，线程池中的线程数量 < 最大线程数，创建新的线程。
4. 如果线程池中的线程数量 > 核心线程数，缓冲队列满了，线程池中的线程数量 = 最大线程数，通过handler所指定的策略来处理任务。
5. 如果线程池中的线程数量 > 核心线程数，如果某线程空闲时间超过keepAliveTime，线程将被终止。

#### 4.3.5.2 线程池使用原因

1. 降低资源消耗：提高线程利用率，降低创建和销毁线程的消耗。
2. 提高响应速度：任务来了，直接有线程可用可执行，而不是先创建线程，在执行。
3. 提高线程的可管理性：线程时稀缺资源，使用线程池统一分配调优监控。

#### 4.3.5.3 线程池参数

核心线程数 最大线程数 存活时间 等待队列 线程工厂 任务拒绝策略

#### 4.3.5.4 线程池种类

**newCachedThreadPool** 

创建一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。 调用 execute 将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。 因此，长时间保持空闲的线程池不会使用任何资源。 

**newFixedThreadPool** 

创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这些线程。在任意点，在大多数 nThreads 线程会处于处理任务的活动状态。如果在所有线程处于活动状态时提交附加任务，则在有可用线程之前，附加任务将在队列中等待。如果在关闭前的执行期间由于失败而导致任何线程终止，那么一个新线程将代替它执行后续的任务（如果需要）。在某个线程被显式地关闭之前，池中的线程将一直存在。 

**newScheduledThreadPool** 

创建一个线程池，它可安排在给定延迟后运行命令或者定期地执行。 

**newSingleThreadExecutor** 

Executors.newSingleThreadExecutor()返回一个线程池（这个线程池只有一个线程） ,这个线程池可以在线程死后（或发生异常时）重新启动一个线程来替代原来的线程继续执行下去！ 

### 4.3.6 volatile

volatile 保证属性的可见性，对于加了关键字的属性，在对这个属性进行修改时，会直接将CPU高级缓存的数据写回到主内存，对这个变量的读取也会直接从主内存中读取，从而保证了可见性。底层是通过内存屏障来实现的。所以会禁止指令重排，也保证了有序性。

### 4.3.7 锁

#### 4.3.7.1 Synchonized

##### 4.3.7.1.1 synchronized 关键字的了解

synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。

另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。

如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized 效率低的原因。

庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销 。

##### 4.3.7.1.2 synchronized 的使用

修饰实例方法: 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁

修饰静态方法：也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，**因为访问静态** **synchronized** **方法占用的锁是当前类的锁，而访问非静态****synchronized** **方法占用的锁是当前实例对象锁。**

修饰代码块: 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。

**总结：** synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。

##### 4.3.7.1.3 synchronized 的实现

1. JVM 每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList 会被大量的并发线程进行 CAS 访问，为了降低对尾部元素的竞争， JVM 会将一部分线程移动到 EntryList 中作为候选竞争线程。

2. Owner 线程会在 unlock 时，将 ContentionList 中的部分线程迁移到 EntryList 中，并指定EntryList 中的某个线程为 OnDeck 线程（一般是最先进去的那个线程）。

3. Owner 线程并不直接把锁传递给 OnDeck 线程，而是把锁竞争的权利交给 OnDeck，OnDeck 需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM 中，也把这种选择行为称之为“竞争切换”。 

4. OnDeck 线程获取到锁资源后会变为 Owner 线程，而没有得到锁资源的仍然停留在 EntryList中。如果 Owner 线程被 wait 方法阻塞，则转移到 WaitSet 队列中，直到某个时刻通过 notify或者 notifyAll 唤醒，会重新进去 EntryList 中。

5. 处于 ContentionList、 EntryList、 WaitSet 中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux 内核下采用 pthread_mutex_lock 内核函数实现的）。

6. Synchronized 是非公平锁。 Synchronized 在线程进入 ContentionList 时， 等待的线程会先尝试自旋获取锁，如果获取不到就进入 ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占 OnDeck 线程的锁资源。

7. 每个对象都有个 monitor 对象，加锁就是在竞争 monitor 对象，代码块加锁是在前后分别加上 monitorenter 和 monitorexit 指令来实现的，方法加锁是通过一个标记位来判断的

8. synchronized 是一个重量级操作，需要调用操作系统相关接口，性能是低效的，有可能给线程加锁消耗的时间比有用操作消耗的时间更多。

9. Java1.6， synchronized 进行了很多的优化， 有适应自旋、锁消除、锁粗化、轻量级锁及偏向锁等，效率有了本质上的提高。在之后推出的 Java1.7 与 1.8 中，均对该关键字的实现机理做了优化。引入了偏向锁和轻量级锁。都是在对象头中有标记位，不需要经过操作系统加锁。

10. 锁可以从偏向锁升级到轻量级锁，再升级到重量级锁。这种升级过程叫做锁膨胀；

11. JDK 1.6 中默认是开启偏向锁和轻量级锁，可以通过-XX:-UseBiasedLocking 来禁用偏向锁。 

##### 4.3.7.1.4 Synchonized 和 ReentrantLock的区别

1. 前者是关键字，后者是一个类。
2. 前者会自动的加锁和释放锁，后者需要程序员手动的加锁和释放锁。
3. 前者是JVM层面，后者API层面。
4. 前者非公平锁，后者都可以。
5. 前者所的是对象，锁信息保存在对象头中，后者通过代码中的state标识来标识锁的状态。
6. 前者有锁升级的过程

##### 4.3.7.1.5 Synchonized 锁升级的过程

1. 无锁
2. 偏向锁：有一个线程来获取锁就会升级成偏向锁，在锁对象的对象头记录一下当前获取到锁的线程ID，该线程下次如果又来获取该锁就可以直接获取到了。
3. 轻量级锁：如果有另一个线程来竞争锁，偏向锁就会升级成轻量级锁，轻量级锁底层是通过自旋锁实现的，并不会阻塞线程
4. 重量级锁：如果自旋次数过多仍没有获取到锁，则会升级为重量级锁，重量级锁会导致线程阻塞
5. 自旋锁：自旋锁就是线程在获取锁的过程中，不会去阻塞线程，也就无所谓唤醒线程，阻塞和唤醒都需要操作系统来进行，比较消耗时间，自旋锁就是线程通过CAS获取一个预期的标记，如果没有获取到，则循环等待，如果获取到了就表示获取到了锁，这个过程线程一直在运行中，没有占用太多系统资源，轻量。

#### 4.3.7.2 乐观锁

乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新），如果失败则要重复读-比较-写的操作。

java 中的乐观锁基本都是通过 CAS 操作实现的， CAS 是一种更新的原子操作，比较当前值跟传入值是否一样，一样则更新，否则失败。 

#### 4.3.7.3 悲观锁

悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会 block 直到拿到锁。java中的悲观锁就是Synchronized,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，才会转换为悲观锁，如 RetreenLock。 

#### 4.3.7.4 自旋锁

自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。线程自旋是需要消耗 cup 的，说白了就是让 cup 在做无用功，如果一直获取不到锁，那线程也不能一直占用 cup 自旋做无用功，所以需要设定一个自旋等待的最大时间。如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。

**自旋锁的优缺点**

自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会导致线程发生两次上下文切换！但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用 cpu 做无用功，占着 XX 不 XX，同时有大量线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要 cup 的线程又不能获取到 cpu，造成 cpu 的浪费。所以这种情况下我们要关闭自旋锁；

#### 4.3.7.5 非公平锁和公平锁

非公平锁 加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待

JVM 按随机、就近原则分配锁的机制则称为不公平锁， ReentrantLock 在构造函数中提供了是否公平锁的初始化方式，默认为非公平锁。 非公平锁实际执行的效率要远远超出公平锁，除非程序有特殊需要，否则最常用非公平锁的分配机制。

公平锁  加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得

公平锁指的是锁的分配机制是公平的，通常先对锁提出获取请求的线程会先被分配到锁，ReentrantLock 在构造函数中提供了是否公平锁的初始化方式来定义公平锁。 

#### 4.3.7.6 可重入锁

本文里面讲的是广义上的可重入锁，而不是单指 JAVA 下的 ReentrantLock。 可重入锁，也叫做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。在 JAVA 环境下 ReentrantLock 和 synchronized 都是 可重入锁。 

#### 4.3.7.7 读写锁

为了提高性能， Java 提供了读写锁，在读的地方使用读锁，在写的地方使用写锁，灵活控制，如果没有写锁的情况下，读是无阻塞的,在一定程度上提高了程序的执行效率。 读写锁分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由 jvm 自己控制的，你只要上好相应的锁即可。

**读锁** 如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁

**写锁** 如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁！

#### 4.3.7.8 共享锁和独占锁

**独占锁**  独占锁模式下，每次只能有一个线程能持有锁， ReentrantLock 就是以独占方式实现的互斥锁。独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。

**共享锁** 共享锁则允许多个线程同时获取锁，并发访问 共享资源，如： ReadWriteLock。 共享锁则是一种乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。

#### 4.3.7.9 锁优化

**减少锁持有时间**只用在有线程安全要求的程序上加锁

**减小锁粒度**将大对象（这个对象可能会被很多线程访问），拆成小对象，大大增加并行度，降低锁竞争。降低了锁的竞争，偏向锁，轻量级锁成功率才会提高。最最典型的减小锁粒度的案例就是ConcurrentHashMap。

**锁分离**最常见的锁分离就是读写锁 ReadWriteLock，根据功能进行分离成读锁和写锁，这样读读不互斥，读写互斥，写写互斥，即保证了线程安全，又提高了性能。读写分离思想可以延伸，只要操作互不影响，锁就可以分离。比如LinkedBlockingQueue 从头部取出，从尾部放数据

**锁粗化**通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短，即在使用完公共资源后，应该立即释放锁。但是，凡事都有一个度， 如果对同一个锁不停的进行请求、同步和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化 。

**锁消除**锁消除是在编译器级别的事情。 在即时编译器时，如果发现不可能被共享的对象，则可以消除这些对象的锁操作，多数是因为程序员编码不规范引起。

#### 4.3.7.9 死锁

必要条件

1. 互斥条件：该资源任意一个时刻只由一个线程占用。
2. 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
3. 不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4. 循环等待条件:若干线程之间形成一种头尾相接的循环等待资源关系。

**如何预防死锁？** 破坏死锁的产生的必要条件即可：

1. **破坏请求与保持条件** ：一次性申请所有的资源。
2. **破坏不剥夺条件** ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
3. **破坏循环等待条件** ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。

### 4.3.8 实现多线程的方法

#### 4.3.8.1 继承 Thread 类

Thread 类本质上是实现了 Runnable 接口的一个实例，代表一个线程的实例。 启动线程的唯一方法就是通过 Thread 类的 start()实例方法。 start()方法是一个 native 方法，它将启动一个新线程，并执行 run()方法。

1. 创建一个继承于Thread类的子类
2. 重写Thread类的run（）—>将此线程执行的操作声明在run()中
3. 创建Thread类的子类的对象
4. 通过此对象调用start（）

```java
public class MyThread extends Thread {
    public void run() { 
        System.out.println("MyThread.run()"); 
    } 
}
MyThread myThread1 = new MyThread(); 
myThread1.start();
```

#### 4.3.8.2 实现Runnable接口

如果自己的类已经 extends 另一个类，就无法直接 extends Thread，此时，可以实现一个Runnable 接口。 

1. 创建一个实现Runnable接口的类
2. 实现类去实现Runnable中的抽象方法：run( ) （和Thread类似，这里也有一个run方法）
3. 创建实现类的对象
4. 将此对象作为参数传递到Thread类的构造器中，创建Thread类的对象
5. 通过Thread类的对象调用start( )

```java
public class MyThread extends OtherClass implements Runnable { 
    public void run() { 
        System.out.println("MyThread.run()"); 
    } 
}//启动 MyThread，需要首先实例化一个 Thread，并传入自己的 MyThread 实例： 
MyThread myThread = new MyThread(); 
Thread thread = new Thread(myThread); 
thread.start(); 
//事实上，当传入一个 Runnable target 参数给 Thread 后， Thread 的 run()方法就会调用 target.run() 
public void run() { 
    if (target != null) { 
        target.run(); 
    } 
}
```

比较前两种方式

实现的方式没有类的单继承性的局限性。

实现的方式更适合处理多个线程有共享数据的情况。 用继承则需要将数据static

相同点

两种方式都需要重写run()，将线程要执行的逻辑声明在run()中。

方式一的问题在于，需要让当前类 继承于 Thread类，而java又是一个单继承的，这样的话为了创建多线程就会导致无法继承其他的类了

#### 4.3.8.3 ExecutorService、Callable**、** Future 有返回值线程

有返回值的任务必须实现 Callable 接口，类似的，无返回值的任务必须 Runnable 接口。执行Callable 任务后，可以获取一个 Future 的对象，在该对象上调用 get 就可以获取到 Callable 任务返回的 Object 了，再结合线程池接口 ExecutorService 就可以实现传说中有返回结果的多线程了。 

1. 创建一个实现Callable的实现类

2. 实现call方法，将此线程需要执行的操作声明在call()中

3. 创建Callable接口实现类的对象

4. 将此Callable的接口实现类的对象作为参数传递到FutureTask的构造器中，创建FutureTask的对象

5. 将FutureTask的对象作为参数传递到Thread类的构造器中，创建Thread对象，并调用start()

6. （可选）获取Callable中call方法的返回值

   **如何理解实现Callable接口的方式创建多线程比实现Runnable接口创建多线程方式强大？**

1. call()可以有返回值。
2. call()可以抛出异常，被外面的操作捕获，从而获取异常的信息
3. Callable是支持泛型的

#### 4.3.8.4 基于线程池

线程和数据库连接这些资源都是非常宝贵的资源。那么每次需要的时候创建，不需要的时候销毁，是非常浪费资源的。那么我们就可以使用缓存的策略，也就是使用线程池。

```java
// 创建线程池 
ExecutorService threadPool = Executors.newFixedThreadPool(10); 
while(true) { 
    threadPool.execute(new Runnable() { // 提交多个线程任务，并执行 
        @Override 
        public void run() { 
            System.out.println(Thread.currentThread().getName() + " is running .."); 
            try {
                Thread.sleep(3000); 
            } catch (InterruptedException e) { 
                e.printStackTrace(); 
            } 
        } 
    }); 
}
```

### 4.3.9相关函数

#### 4.3.9.1 notify()和notifyAll()有什么区别？

notify可能会导致死锁，而notifyAll则不会

任何时候只有一个线程可以获得锁，也就是说只有一个线程可以运行synchronized 中的代码使用notifyall,可以唤醒所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。

wait() 应配合while循环使用，不应使用if，务必在wait()调用前后都检查条件，如果不满足，必须调用notify()唤醒另外的线程来处理，自己继续wait()直至条件满足再往下执行。

notify() 是对notifyAll()的一个优化，但它有很精确的应用场景，并且要求正确使用。不然可能导致死锁。正确的场景应该是 WaitSet中等待的是相同的条件，唤醒任一个都能正确处理接下来的事项，如果唤醒的线程无法正确处理，务必确保继续notify()下一个线程，并且自身需要重新回到WaitSet中. 

#### 4.3.9.2 sleep()和wait()有什么区别？

1. 对于 sleep()方法，我们首先要知道该方法是属于 Thread 类中的。而 wait()方法，则是属于Object 类中的。 

2. sleep()方法导致了程序暂停执行指定的时间，让出 cpu 该其他线程，但是他的监控状态依然保持者，当指定的时间到了又会自动恢复运行状态 

3. 在调用 sleep()方法的过程中，线程不会释放对象锁。 

4. 而当调用 wait()方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用 notify()方法后本线程才进入对象锁定池准备获取对象锁进入运行状态。 

#### 4.3.9.3 start()和run()有什么区别？

start()方法被用来启动新创建的线程，而且start()内部调用了run()方法，这和直接调用run()方法的效果不一样。当你调用run()方法的时候，只会是在原来的线程中调用，没有新的线程启动，start()方法才会启动新线程 。

#### 4.3.9.4 为什么wait, notify和 notifyAll这些方法不在thread类里面？

明显的原因是JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果线程需要等待某些锁那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁就不明显了。简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象 。

#### 4.3.9.5 为什么wait, notify要在同步块中调用？

1. 只有在调用线程拥有某个对象的独占锁时，才能够调用该对象的wait(),notify()和notifyAll()方法。

2. 如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。

3. 还有一个原因是为了避免wait和notify之间产生竞态条件。wait()方法强制当前线程释放对象锁。这意味着在调用某对象的wait()方法之前，当前线程必须已经获得该对象的锁。因此，线程必须在某个对象的同步方法或同步代码块中才能调用该对象的wait()方法。在调用对象的notify()和notifyAll()方法之前，调用线程必须已经得到该对象的锁。因此，必须在某个对象的同步方法或同步代码块中才能调用该对象的notify()或notifyAll()方法。调用wait()方法的原因通常是，调用线程希望某个特殊的状态(或变量)被设置之后再继续执行。调用notify()或notifyAll()方法的原因通常是，调用线程希望告诉其他等待中的线程:"特殊状态已经被设置"。这个状态作为线程间通信的通道，它必须是一个可变的共享状态(或变量)。

#### 4.3.9.6 interrupted()和isInterrupted()有什么区别？

interrupted() 和 isInterrupted()的主要区别是前者会将中断状态清除而后者不会。Java多线程的中断机制是用内部标识来实现的，调用Thread.interrupt()来中断一个线程就会设置中断标识为true。当中断线程调用静态方法Thread.interrupted()来检查中断状态时，中断状态会被清零。而非静态方法isInterrupted()用来查询其它线程的中断状态且不会改变中断状态标识。简单的说就是任何抛出InterruptedException异常的方法都会将中断状态清零。无论如何，一个线程的中断状态有有可能被其它线程调用中断来改变 。

#### 4.3.9.7 Thread类中的yield方法有什么作用？

Yield方法可以暂停当前正在执行的线程对象，让其它有相同优先级的线程执行。它是一个静态方法而且只保证当前线程放弃CPU占用而不能保证使其它线程一定能占用CPU，执行yield()的线程有可能在进入到暂停状态后马上又被执行。 

#### 4.3.9.8 Java线程池中submit()和execute()方法有什么区别？

两个方法都可以向线程池提交任务，execute()方法的返回类型是void，它定义在Executor接口中, 而submit()方法可以返回持有计算结果的Future对象，它定义在ExecutorService接口中，它扩展了Executor接口，其它线程池类像ThreadPoolExecutor和ScheduledThreadPoolExecutor都有这些方法 。

## 4.4 集合类

### 4.4.1 集合体系

集合主要分为两组，单列集合和双列集合

Collection接口有两个重要子接口List Set，他们的实现子类都是单列集合

Map接口的实现子类都是双列结合，存放键值对

![image-20230316153607640](C:\Users\LWJ\AppData\Roaming\Typora\typora-user-images\image-20230316153607640.png)

### 4.4.2 集合方法

Collection是一个接口，不能实例化，只能通过实现类，以List为例。

add() remove() contains() size() isEmpty() clear() addAll() containsAll() removeAll()

### 4.4.3 迭代器

Collection继承自Iterator，所有实现Collection接口都要实现iterator（）方法

想要遍历先拿到iterator()方法 **快捷键itit**

```java
Iterator iterator = list.iterator();
while(iterator.hasNext()){
    Object obj = iterator.next();
}
```

### 4.4.4 ArrayList

**底层通过数组实现 ，可以传入多个null，线程不安全**

ArrayList维护了一个transient Object类型的数组elementData，不会被序列化

**扩容机制：**

当创建ArratList对象时，如果使用的时无参构造器，则初始elementData容量为0，第一次添加，则扩容elementData为10，再次扩容为1.5倍

若是指定大小的构造器，设定初始大小，扩容时为1.5倍

remove:

复制数组，size-- 最后一位设为null

### 4.4.5 Vector

底层也是protected Object类型的数组elementData

Vector是线程安全的 头部加了synchronized

扩容为2倍，后来可自定义。

### 4.4.6 LinkedList

实现了双向链表和双端队列，可以添加null，线程不安全

底层维护了一个双向链表

初始化时啥也没有

添加第一个节点时，是一个pre和next都为null的节点 size++

### 4.4.7 Set

可以存null，只能有一个，不能重复

添加无序，按照hashcode值排序，所以取出是有序的

**不能使用传统for循环遍历，因为没有get方法**

### 4.4.8 HashSet

**HashSet添加元素过程**

1. HashSet底层时HashMap
2. 添加一个元素时，首先得到hash值，转化为索引值  
3. 找到存储数据表table，看这个索引位置是否已经有存放的元素
4. 如果没有，直接加入
5. 如果有，调用equals比较，如果相同，就放弃添加，如果不同，就添加到最后。
6. 如果一个链表的元素个数到达设定的8，就会扩容，并且table的大小达到64，转化为红黑树。

7. new HashMap();
8. add()
9. put(key, value) value没有意义 占位 
10. putVal(hash(key),key,value) => hash值不是hashcode，经移位得到，null永远在最前面

如果node数组为0，初始化16长度的数组，扩容因子为0.75，也就是第一次扩容发生在12个元素后。

根据hash值计算key的索引位置

如果该位置为空，创建一个新的Node节点（hash值，key，value，next）

如果不为空，判断与头节点是否为同一个对象或者值相同（hash值一样的前提下，key值一样为同一个对象，equals()为值相同）

如果不相同，判断头节点是不是红黑树，红黑树调用putTreeVal()

如果不是红黑树，即为链表，依次比较每一个结点是否相等，都不相同，加到链表最后，相同直接break；

注意：添加后立即判断链表是否达到8个结点，当node>=8且table.size>=64时树化

### 4.4.9 LinkedHashSet

是HashSet的子类，底层为LinkedHashMap，维护了一个数组+双向链表

用链表维护元素的次序，所以插入有序

**原理：每一个Node都会有上一个和下一个添加结点的指针，为Entry结点**

### 4.4.10 Map接口遍历方法

为了方便遍历，将Node结点的key 和 value 地址生成一个Entry放到EntrySet中

1. ```java
   Set keyset = map.keySet();
   for(Object key : keyset){
   	map.get(key);
   }
   ```

2. ```java
   Iterator iterator = keyset.iterator();
   while(iterator.hasNext()){
   	Object key = iterator.next;
   	map.get(key);
   }
   ```

3. ```java
   map.values()
   ```

4. ```java
   Set entryset = map.entrySet();
   for(Object entry: entrySet){
   	Map.Entry m = (Map.Entry) entry;
   	m.getKey()
   	m.getValue()
   }
   ```

### 4.4.11 HashTable

初始化大小为11的Entry数组，加载因子0.75，临界值8，扩容为2倍加一

### 4.4.12 TreeSet

使用无参构造器创建TreeSet时，是默认排序的

TreeSet构造器可以传入比较器指定排序规则

### 4.4.13 Collections工具类

reverse shuffle sort swap max min frequency copy

# 5 算法

## 5.1 查找算法

### 5.1.1 顺序查找

顺序查找又称为线性查找，是一种最简单的查找方法。适用于线性表的顺序存储结构和链式存储结构。

- 基本思路

  从第一个元素m开始逐个与需要查找的元素x进行比较，当比较到元素值相同(即m=x)时返回元素m的下标，如果比较到最后都没有找到，则返回-1。

- **复杂度分析**　

  查找成功时的平均查找长度为： ASL = 每个元素被查找的概率 * 总的元素的个数=1/n*(1+2+3+…+n) = (n+1)/2 ;

  当查找不成功时，需要n+1次比较，时间复杂度为O(n)，所以，顺序查找的时间复杂度为O(n)。

- 优缺点

  缺点：是当n 很大时，平均查找长度较大，效率低；

  优点：是对表中数据元素的存储没有要求。另外，对于线性链表，只能进行顺序查找。

### 5.1.2 二分查找

二分查找，是一种在有序数组中查找某一特定元素的查找算法。

- 基本思路

  用给定值k先与中间结点的关键字比较，中间结点把线形表分成两个子表，若相等则查找成功；若不相等，再根据k与该中间结点关键字的比较结果确定下一步查找哪个子表，这样递归进行，直到查找到或查找结束发现表中没有这样的结点。

- 复杂度分析　

  时间复杂度：折半搜索每次把搜索区域减少一半，时间复杂度为O(logn) 。

  空间复杂度：O(1)。

- 优缺点分析

  当查找表不会频繁有更新、删除操作时，使用折半查找是比较理想的。如果查找表有较频繁的更新、删除操作，维护表的有序会花费比较大的精力，不建议使用该查找方式。

```java
static  int binarySearch1(int arr[],int len,int target){
		/*初始化左右搜索边界*/
	    int left=0,right=len-1;
	    int mid;
	    while(left<=right){
	    	/*中间位置：两边界元素之和/2向下取整*/
	        mid=(left+right)/2;
	        /*arr[mid]大于target，即要寻找的元素在左半边，所以需要设定右边界为mid-1，搜索左半边*/
	        if(target<arr[mid]){
	            right=mid-1;
	        /*arr[mid]小于target，即要寻找的元素在右半边，所以需要设定左边界为mid+1，搜索右半边*/
            }else if(target>arr[mid]){
	            left=mid+1;
	        /*搜索到对应元素*/
	        }else if(target==arr[mid]){
	            return mid;
	        }
	    }
	    /*搜索不到返回-1*/
	    return -1;
	}
```

### 5.1.3 插值查找

在二分查找中，每次都是从待查找序列的中间点开始查找，这样的做法在正确性上固然没什么问题，但假如要查找的值距离某个边界比较近，还从中间点开始查找，就有点浪费时间了。举个例子来说说明，假如在在一个{1,2…,100}的数组中，要查找88这个值，还一直采用和中间点比较的策略，就显得不太明智，因为明显可以明显从较为靠后的位置去检索。为了克服这种弊端， 引入了插值查找。

- 基本思路

  插值查找是根据要查找的关键字key与查找表中最大最小记录的关键字比较后的 查找方法，其核心就在于插值的计算公式 (key-array[low])/(array[high]-array[low])*(high-low)。简而言之，基于二分查找算法，将查找点的选择改进为自适应选择。

- 复杂度分析　

  时间复杂性：如果元素均匀分布，则O(log(logn))，在最坏的情况下可能需要O(n)。

  空间复杂度：O(1)。

- 优缺点分析

  对于长度比较长、关键字分布又比较均匀的查找表来说，插值查找算法的平均性能比折半查找要好的多。反之，数组中如果分布非常不均匀，那么插值查找未必是很合适的选择。

```java
private static int insertSearch1(int arr[],int target){
		/*初始化左右搜索边界*/
	    int left=0,right=arr.length-1;
	    int mid;
	    while(left<=right){
	        mid=left+(target-arr[left])/(arr[right]-arr[left])*(right-left);
	        /*arr[mid]大于target，即要寻找的元素在左半边，所以需要设定右边界为mid-1，搜索左半边*/
	        if(target<arr[mid]){
	            right=mid-1;
	        /*arr[mid]小于target，即要寻找的元素在右半边，所以需要设定左边界为mid+1，搜索右半边*/
            }else if(target>arr[mid]){
	            left=mid+1;
	        /*搜索到对应元素*/
	        }else if(target==arr[mid]){
	            return mid;
	        }
	    }
	    /*搜索不到返回-1*/
	    return -1;
	}
```

### 5.1.4 斐波那契查找

和前面的二分查找、插值查找相比，斐波那契查找是类似的，不过换了一种寻找mid点的方法。顾名思义，该种查找方法中，使用到了斐波那契数列，斐波那契数列的形式是：1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89…….（从第三个数开始，后边每一个数都是前两个数的和）。

- 基本思路

  在斐波那契数列中的元素满足这样的关系：F[k]=F[k-1]+F[k-2]，此处将这个数组稍微改一下，改成：（F[k]-1）=（F[k-1]-1）+（F[k-2]-1）+1，找出一个中间mid值，以便将数组按斐波那契数列的规律，分割成两部分。

- 复杂度分析

  最坏情况下，时间复杂度为O(logn)，且其期望复杂度也为O(logn)。

```java
public class FibonacciSearch {
	
	public static int FLENGTH = 20;
	public static void main(String[] args) {
		int [] arr = {1,8,10,89,100,134};
		int target = 89;
		System.out.println("目标元素在数组中位置是：" + fibSearch(arr, target));		
	}

	public static int[] fib() {
		int[] f = new int[FLENGTH];
		f[0] = 1;
		f[1] = 1;
		for (int i = 2; i < FLENGTH; i++) {
			f[i] = f[i-1] + f[i-2];
		}
		return f;
	}
	
	public static int fibSearch(int[] arr, int target) {
		int low = 0;
		int high = arr.length - 1;
		int k = 0; 
		int mid = 0; 
		int f[] = fib();
		/*获取最相邻的斐波那契数组中元素的值，该值略大于数组的长度*/
		while(high > f[k] - 1) {
			k++;
		}
		/*因为 f[k]值可能大于arr的长度。如果大于时，需要构造一个新的数组temp[]，将arr数组中的元素拷贝过去，不足的部分会使用0填充*/
		int[] temp=Arrays.copyOf(arr, f[k]);
		/*然后将temp后面填充的0，替换为最后一位数字
		 *如将temp数组由{1,8,10,89,100,134,0,0}变换为{1,8,10,89,100,134,134,134}*/
		for(int i = high + 1; i < temp.length; i++) {
			temp[i] = arr[high];
		}
		
		while (low <= high) { 
			mid = low + f[k - 1] - 1;
			if(target < temp[mid]) { 
				high = mid - 1;
				/*因为f[k]=f[k-1]+f[k-2]，所以k--就相当于取temp数组的左边部分*/
				k--;
			} else if ( target > temp[mid]) { 
				low = mid + 1;
				/*同理，f[k]=f[k-1]+f[k-2]，k -= 2就相当于取temp数组的右边部分*/
				k -= 2;
			} else {
				/*原arr数组中的值*/
				if(mid <= high){
					return mid;
				/*在temp中，扩展出来的高位的值*/
				}else{
					return high;
				}
			}
		}
		return -1;
	}
}
```

### 5.1.5 数表查找

```java
public class BinarySortTree {
    
    public static void main(String[] args) {
        int[] array = {35,76,6,22,16,49,49,98,46,9,40};
        BinaryTree root = new BinaryTree(array[0]);
        for(int i = 1; i < array.length; i++){
            createBST(root, array[i]);
        }
        System.out.println("中序遍历结果：");
        midOrderPrint(root);
        System.out.println();
        searchBST(root, 22, null);
        searchBST(root, 100, null);
    }
    
    /*创建二叉排序树*/
    public static void createBST(BinaryTree root, int element){
        BinaryTree newNode = new BinaryTree(element);
        if(element > root.value){
            if(root.right == null)
                root.right = newNode;
            else
                createBST(root.right, element);
        }else if(element < root.value){
            if(root.left == null)
                root.left = newNode;
            else
                createBST(root.left, element);
        }else{
            System.out.println("该节点" + element + "已存在");
            return;
        }
    }
    
    /*二叉树中查找元素*/
    public static void searchBST(BinaryTree root, int target, BinaryTree p){
        if(root == null){
            System.out.println("查找"+target+"失败");
        }else if(root.value == target){
            System.out.println("查找"+target+"成功");
        }else if(root.value >= target){
            searchBST(root.left, target, root);
        }else{ 
            searchBST(root.right, target, root);
        }
    }
    
    /*二叉树的中序遍历*/
    public static void midOrderPrint(BinaryTree rt){
        if(rt != null){
        	midOrderPrint(rt.left);
            System.out.print(rt.value + " ");
            midOrderPrint(rt.right);	
        }
    }
}
```

### 5.1.6 分块查找

  分块查找，顾名思义，要先将所有元素按大小进行分块，然后在块内进行查找。在分块时，块内的元素不一定是有序的，只要一个块内的元素在同一区间就行。用较标准的语言描述是：算法的思想是将n个数据元素"按块有序"划分为m块（m≤n）。每一块中的结点不必有序，但块与块之间必须"按块有序"，每个块内的的最大元素小于下一块所有元素的任意一个值。
  所以，在使用分块查找时，分成了两步：
   1>找到元素可能在的块。
   2>在对应的块内查找元素。

### 5.1.7 哈希查找

```java
public class HashSearch {

    /*待查找序列*/
    static int[] array = {13, 29, 27, 28, 26, 30, 38};
    /* 初始化哈希表长度，此处哈希表容量设置的和array长度一样。
     * 其实正常情况下，哈希表长度应该要长于array长度，因为使用
     * 开放地址法时，可能会多使用一些空位置
     */
    static int hashLength = 7;
    static int[] hashTable = new int[hashLength];

    public static void main(String[] args) {
        /*将元素插入到哈希表中*/
        for (int i = 0; i < array.length; i++) {
        	insertHashTable(hashTable, array[i]);
        }
        System.out.println("哈希表中的数据：");
        printHashTable(hashTable);
        
        int data = 28;
        System.out.println("\n要查找的数据"+data);
        int result = searchHashTable(hashTable, data);
        if (result == -1) {
            System.out.println("对不起，没有找到！");
        } else {
            System.out.println("在哈希表中的位置是：" + result);
        }
    }

    /*将元素插入到哈希表中*/
    public static void insertHashTable(int[] hashTable, int target) {
        int hashAddress = hash(hashTable, target);

        /*如果不为0，则说明发生冲突*/
        while (hashTable[hashAddress] != 0) {
            /*利用开放定址法解决冲突，即向后寻找新地址*/
            hashAddress = (++hashAddress) % hashTable.length;
        }

        /*将元素插入到哈希表中*/
        hashTable[hashAddress] = target;
    }

    public static int searchHashTable(int[] hashTable, int target) {
        int hashAddress = hash(hashTable, target);

        while (hashTable[hashAddress] != target) {
            /*寻找原始地址后面的位置*/
            hashAddress = (++hashAddress) % hashTable.length;
            /*查找到开放单元(未存放元素的位置)或 循环回到原点，表示查找失败*/
            if (hashTable[hashAddress] == 0 || hashAddress == hash(hashTable, target)) {
                return -1;
            }
        }
        return hashAddress;
    }

    /*用除留余数法计算要插入元素的地址*/
    public static int hash(int[] hashTable, int data) {
        return data % hashTable.length;
    }

    public static void printHashTable(int[] hashTable) {
    	for(int i=0;i<hashTable.length;i++)
    		System.out.print(hashTable[i]+" ");
    }
}
```

## 5.2 排序算法

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210316213527859.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzIwNzAyNQ==,size_16,color_FFFFFF,t_70#pic_center)

# 6. Spring

## 6.1 循环依赖

### 6.1.1 spring创建bean的流程

1. spring启动时会根据配置文件或启动类把所有的bean注册成**bean定义**（就是映射<bean>标签属性的java类）
2. 遍历bean定义中的beanName，调用BeanFactory#getBean(beanName)方法创建、初始化并返回bean实例

### 6.1.2 getBean方法大致流程：

1. **先从缓存拿**（从**第一层**到第三层缓存中依次获取）
2. 没有就去创建：把beanName标记为正在创建中，**通过其定义里的class找到构造器方法反射创建实例**
3. 如果此beanName为正在创建中，则把其对象工厂放入第三层缓存
4. **对实例初始化（获取此bean中有@Autowired等注解的成员变量，从所有bean定义中找出此类型的beanName，又通过BeanFactory#getBean方法获取实例，然后反射设值成员变量）**，移除正在创建中的标记，**把实例放入第一层缓存**，移除第二、三层中的缓存，最后返回实例

### 6.1.3 Spring中单例Bean的三级缓存

第一级缓存〈也叫单例池）singletonObjects:存放已经经历了完整生命周期的Bean对象

第二级缓存: earlySingletonObjects，存放早期暴露出来的Bean对象，Bean的生命周期未结束（属性还未填充完整）

第三级缓存: Map<String, ObiectFactory<?>> singletonFactories，存放可以生成Bean的工厂

### 6.1.4 执行过程

A创建过程中需要B，于是A将自己放到三级缓存里面，去实例化B

B实例化的时候发现需要A，于是B先查一级缓存，没有，再查二级缓存，还是没有，再查三级缓存，找到了A然后把三级缓存里面的这个A放到二级缓存里面，并删除三级缓存里面的A

B顺利初始化完毕，将自己放到一级缓存里面（此时B里面的A依然是创建中状态）然后回来接着创建A，此时B已经创建结束，直接从一级缓存里面拿到B，然后完成创建，并将A放到一级缓存中。

- 第一层缓存：最基础的缓存，创建完并初始化（createBean）后的bean实例会放入，项目启动完成后获取bean实例时从此获取
- 第三层缓存：创建bean过程中用于处理循环依赖的临时缓存，由于只有在初始化时才知道有没有循环依赖，所以通过ObjectFactory临时“存储”刚创建完的bean，并延迟触发循环依赖时被引用的bean需要赋值当前bean时去获取当前bean的逻辑，且获取对象会作为当前bean的最终对象
- 第二级缓存：创建bean过程中用于处理循环依赖的临时缓存，搭配第[三层缓存](https://www.zhihu.com/search?q=三层缓存&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2443911807})，用于其ObjectFactory返回对象的缓存，保证多个关联对象对当前bean的引用为同一个

## 6.2 spring springboot springmvc

spring是一个开源的容器框架。可以接管web层，业务层，dao层，持久层的组件。它可以配置各种bean，和维护bean和bean之间的关系，其核心就是控制反转和面向切面编程，简单的说就是一种分层的轻量级的开源框架。

springmvc属于springframework的后续产品，已经在融合在spring web flow里面，它是一种mvc框架，用于替代serviet处理，响应请求，获取表单参数，表单校验等。

springboot是一个微服务框架，延续了spring框架的核心思想ioc和aop，简化了应用的开发和部署。springboot是为了简化spring应用的创建、运行、调试、部署等而出现的，使用它可以做到专注于spring应用的开发，而无需过多关注xml的配置。它提供了一堆依赖打包，并已经按照使用习惯解决了依赖问题。

## 6.3 bean的生命周期

1. 解析xml配置或者注解配置的类，得到BeanDefinition
2. 通过BeanDefinition反射创建Bean对象
3. 对Bean对象进行属性填充
4. 回调实现了Aware接口的方法，如BeanNameAware
5. 调用BeanPostProcessor的初始化前方法
6. 调用init初始化方法
7. 调用BeanPostProcessor的初始化后方法，此时会进行AOP
8. 将创建的Bean对象放入一个Map中
9. 业务使用Bean对象
10. Spring容器关闭时调用DisposableBean的destory()方法

## 6.4 IOC

要了解控制反转，需要先了解软件设计的一个重要思想：依赖倒置原则。
　　什么是依赖倒置原则？假设我们设计一辆汽车：先设计轮子，然后根据轮子大小设计底盘，接着根据底盘设计车身，最后根据车身设计好整个汽车。这里就出现了一个“依赖”关系：汽车依赖车身，车身依赖底盘，底盘依赖轮子。但这种设计维护性很低。

　        换一种思路：我们先设计汽车的大概样子，然后根据汽车的样子来设计车身，根据车身来设计底盘，最后根据底盘来设计轮子。这时候，依赖关系就倒置过来了：轮子依赖底盘，底盘依赖车身，车身依赖汽车。

　由此我们可以看到，仅仅是为了修改轮胎的构造函数，这种设计却需要修改整个上层所有类的构造函数！在软件工程中，这样的设计几乎是不可维护的——在实际工程项目中，有的类可能会是几千个类的底层，如果每次修改这个类，我们都要修改所有以它作为依赖的类，那软件的维护成本就太高了。

所以我们需要进行控制反转（IoC），即上层控制下层，而不是下层控制着上层。我们用依赖注入（Dependency Injection）这种方式来实现控制反转。所谓依赖注入，就是把底层类作为参数传入上层类，实现上层类对下层类的“控制”。

## 6.5 AOP

   （1） 面向切面编程（AOP）完善spring的依赖注入（DI），面向切面编程在spring中主要表现为两个方面 1.面向切面编程提供声明式事务管理 2.spring支持用户自定义的切面 。

（2）面向切面编程（aop）是对面向对象编程（oop）的补充， 面向对象编程将程序分解成各个层次的对象，面向切面编程将程序运行过程分解成各个切面。 
（3）AOP从程序运行角度考虑程序的结构，提取业务处理过程的切面，oop是静态的抽象，aop是动态的抽象， 是对应用执行过程中的步骤进行抽象，，从而获得步骤之间的逻辑划分。

想象下面的场景，开发中在多个模块间有某段重复的代码，我们通常是怎么处理的？显然，没有人会靠“复制粘贴”吧。在传统的面向过程编程中，我们也会将这段代码，抽象成一个方法，然后在需要的地方分别调用这个方法，这样当这段代码需要修改时，我们只需要改变这个方法就可以了。然而需求总是变化的，有一天，新增了一个需求，需要再多出做修改，我们需要再抽象出一个方法，然后再在需要的地方分别调用这个方法，又或者我们不需要这个方法了，我们还是得删除掉每一处调用该方法的地方。实际上涉及到多个地方具有相同的修改的问题我们都可以通过 AOP 来解决。

## 6.6 设计模式

单例模式：bean默认情况下都是单例的。

工厂模式：通过beanfactory和applicationcontext来生产bean对象

代理模式：最常见的AOP就是这样实现的。

模板方法模式：一些对数据库操作的类，比如jdbctemplate，因为查询数据库的建立连接、执行查询、关闭连接非常适用于模板方法。

## 6.7 JDK代理和CGLIB代理

JDK动态代理主要是针对类实现了某个接口，AOP则会使用动态代理。它基于反射机制实现，生成一个实现同样接口的一个代理类，然后通过重写方法的方式，实现对代码的增强。

而如果这个类没有实现接口，AOP则会使用CGLIB代理。他的底层原理是基于asm的第三方框架，通过修改字节码生成一个子类，然后重写父类的方法，实现对代码的增强。

## 6.8 FactoryBean 和 BeanFactory区别

BeanFactory是bean的工厂，applicationcontext的父类，ioc容器的核心，负责管理和生产对象。

FactoryBean是bean，可以通过实现FactoryBean 接口定制实例化bean的逻辑。

## 6.9 Springboot启动流程

1.准备环境，根据不同的环境创建不同的environment

2.准备，加载上下文，为不同的环境选择不同的springcontext，然后加载资源，配置bean

3.初始化，这个阶段刷新spring context，启动应用

4.最后结束流程

## 6.10 SpringBoot 请求参数接收

@RequestMapping

- 简单参数：定义方法形参，请求参数名与形参变量名一致。如果不一致，@RequestParam手动映射
- 实体参数
- 数组集合参数：数组直接封装，集合@RequestParam绑定关系
- 日期参数：@DateTimeFormat
- JSON参数：@RequestBody
- 路径参数：@PathVariable

## 6.10 SpringBoot 响应数据

@RestController = @Controller+@ResponseBody

将对象自动转为JSON返回

## 6.11 Web开发三层架构

controller：控制层，接收前端发送的

# 7. Redis

## 7.1 如何保证数据库与缓存的一致性？

由于缓存和数据库是分开的，无法做到原子性的同时进行数据修改，可能出现缓存更新失败，或者数据库更新失败的情况，这时候会出现数据不一致，影响前端业务

- 先更新数据库，再更新缓存。缓存可能更新失败，读到老数据
- 先删缓存，再更新数据库。并发时，读操作可能还是会将旧数据读回缓存
- 先更新数据库，再删缓存。也存在缓存删除失败的可能

最经典的缓存+数据库读写的模式，**Cache Aside Pattern**。

读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。

更新的时候，先更新数据库，然后再删除缓存。

**为什么是删除而不是更新?**

删除更加轻量，延迟加载的一种实现，更新可能涉及多个表、比较耗时

**延时双删:**先删除缓存，再更新数据库，休眠1s、再次删除缓存。写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据，并发还是可能读到旧值覆盖缓存

终极方案

将访问操作串行化

- 先删缓存，将更新数据库的操作放进有序队列中
- 从缓存查不到的查询操作，都进入有序队列

会面临的问题

- 读请求积压，大量超时，导致数据库的压力: 限流、熔断
- 如何避免大量请求积压: 将队列水平拆分，提高并行度
- 保证相同请求路由正确。

## 7.2 redis的持久化机制

RDB：将某一时刻的内存快照，以二进制的方式写入磁盘

手动触发：

- save命令，使redis处于阻塞状态，直到RDB持久化完成，才会响应其它客户端发来的命令
- bgsave命令，fork出一个子进程执行持久化，主进程只在fork过程中有短暂的阻塞，子进程创建之后，主进程就可以响应客户端的请求。**cow 写时拷贝策略：**父进程执行写命令，不操作共享内存，将数据拷贝出来一个副本，对副本进行修改。保证某一时刻快照的准确性，起到数据隔离的作用。

自动触发：

- save m n: 在m 秒内，如果有n 个键发生改变，则自动触发持久化，通过bgsave执行，如果设置多个、只要满足其一就会触发，配置文件有默认配置(可以注释掉)
- flushall: 用于清空redis所有的数据库，flushdb清空当前redis所在库数据(默认是0号数据库)，会清空RDB文件，同时也会生成dump.rdb、内容为空
- 主从同步: 全量同步时会自动触发bgsave命令，生成rdb发送给从节点

优点:

1. 整个Redis数据库将只包含一个文件 dump.rdb，方便持久化。
2. 容灾性好，方便备份。
3. 性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何IO 操作，保证了 redis 的高性能
4. 相对于数据集大时，比AF 的启动效率更高

缺点:

1. 数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候)
2. 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。会占用cpu

AOF：Append Only File 以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录，调操作系统命令进程刷盘

1. 所有的写命令会追加到 AOF 缓冲中。
2. AOF 缓冲区根据**对应的策略**向硬盘进行同步操作.
3. 随着AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。
4. 当 Redis 重启时，可以加载 AOF 文件进行数据恢复

同步策略：（刷盘命令fsync）

- 每秒同步:异步完成，效率非常高，一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。
- 每修改同步:同步持久化，每次发生的数据变化都会被立即记录到磁盘中，最多丢一条
- 不同步:由操作系统控制，可能丢失较多数据

优点:

1. 数据安全
2. 通过 append 模式写文件，即使中途服务器宕机也不会破坏已经存在的内容，可以通过 redis-check-aof 工具
   解决数据一致性问题。
3. AOF机制的 rewrite 模式。定期对AOF文件进行重写，以达到压缩的目的

缺点：

- AOF 文件比 RDB 文件大，且恢复速度慢。
- 数据集大的时候，比 rdb 启动效率低l,
- 运行效率没有RDB高

两者使用对比：

- AOF文件比RDB更新频率高，优先使用AOF还原数据
- AOF比RDB更安全也更大
- RDB性能比AOF好
- 如果两个都配了优先加载AOF

## 7.3 缓存雪崩、缓存穿透、缓存击穿

缓存雪崩是指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉

解决方案:

- 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生
- 给每一个缓存数据增加相应的缓存标记，记录缓存是否失效，如果缓存标记失效，则更新数据缓存。
- 缓存预热
- 互斥锁

缓存穿透是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

解决方案:

- 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截
- 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒(设置太长会导致正常情况也没法使用)。这样可以防止攻击用户反复用同一个id暴力攻击
- 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个bitmap 拦载掉，从而游免了对底层存储系统的查询压力

缓存击穿是指缓存中没有但数据库中有的数据(-般是绣存时间到期)，这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。

解决方案

- 设置热点数据永远不过期。
- 加互斥锁

# 8. Mysql

## 8.1 MySQL中幻读是如何解决的

在我们的数据库隔离级别中幻读的解决是在串行化的级别下进行处理的，虽然这种方法可以解决幻读，但是这种方法在高并发下效率是非常低的，经过学习了解到两种解决幻读的方法：加间隙锁和MVCC。

**加间隙锁**
间隙锁：将数据分为不同区间，对该区间进行加锁。作用在索引上，其目的是为了防止同一事物的两次当前读出现幻读的情况。如果对一条记录添加了间隙锁，并不会影响其他事务对这条记录加记录锁或者继续加gap锁。
比如说我们有1,3,5,10,12这几条数据:

在当前事务对5-9中的数据进行一次查询并添加间隙锁后，另一个事务想要在5-9这个范围中添加数据是会阻塞的或者说添加失败。也就是说使用间隙锁后，其他事务就不能在加锁的范围中添加数据，这样就可以防止幻读的产生

**MVCC**
MVCC也就是多版本并发控制，不需要通过加锁手段就能读到正确版本的数据，其存在目的是在保证数据一致性的前提下提供一种高并发的访问性能。
换言之，就是为了查询一些正在被另一个事务更新的行，并且获取到更新前的值，这样在做查询时就不用等待另一个事务释放锁。

MVCC实现原理：隐藏字段，undolog，ReadView
**隐藏字段**：在InnoDB存储引擎中，对于每一条记录都会有隐藏字段，包括ROWID，事务ID（最新一次被哪个事务修改），回滚指针

**ReadView**： 当前数据的快照

在READ COMMITTED隔离级别下，一个事务执行过程中每次执行SELECT操作都会生成一个ReadView，ReadView本身就保证了事务不可以读取到未提交的事务做出的修改，也就避免了脏读现象
在REPETABLE READ隔离级别下，一个事务执行过程中只有第一次执行SELECT操作时才会生成一个ReadView，之后的SELECT操作都是复用这个ReadView，这也就避免了不可重复度和幻读
ReadView规则
ReadView到底是怎么避免幻读的，这就需要知道ReadView都包括什么：

ReadView中包括有：生成ReadView的当前事务，生成ReadVIew时活跃（尚未提交）的事务列表（事务ID从小到大进行排列），以及列表中的最小事务ID（up_limit_id），以及下一个尚未分配过的事务ID（low_limit_id）

详细规则：

如果所查询的数据的隐藏字段中的事务ID就是当前ReadView中的事务ID，则表示当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问到

如果所查询的数据的隐藏字段中的事务ID小于当前ReadView中的up_limit_id，则表示所查询数据是被修改并已经提交的，所以该版本可以被当前事务访问到

如果所查询的数据的隐藏字段中的事务ID大于当前ReadView中的low_limit_id，则表示所查询的数据是在当前事务之后被修改过的，所以不能被当前事务访问到

如果所查询的数据的隐藏字段中的事务ID在up_limit_id和low_limit_id范围之内：

如果所查询的数据的隐藏字段中的事务ID和范围中的某个事务ID相同，则表示修改了数据的事务还是活跃的，没有提交，所以不能被当前事务访问
如果所查询的数据的隐藏字段中的事务ID和范围中的某个事务ID没有相同的，则表示事务已经提交，所以可以被当前事务访问到
**MVCC执行流程**
开启事务时会有一个事务ID（单纯的查询事务ID为0）
获取ReadView
查询得到的数据与ReadView中事务版本号进行比较
如果不符合ReadView规则，则要从undo log中获取历史快照
最后返回符合规则的数据

## 8.2 mysql优化

**1.explain**

做MySQL优化，我们要善用EXPLAIN查看SQL执行计划。

- **type列，**连接类型。一个好的SQL语句至少要达到range级别。杜绝出现all级别。
- **key列，**使用到的索引名。如果没有选择索引，值是NU  LL。可以采取强制索引方式。
- **key_len列，**索引长度。
- **rows列，**扫描行数。该值是个预估值。
- **extra列，**详细说明。注意，常见的不太友好的值，如下：Using filesort，Using temporary。

**2.sql语句中IN包含的值不应过多**

MySQL对于IN做了相应的优化，即将IN中的常量全部存储在一个数组里面，而且这个数组是排好序的。但是如果数值较多，产生的消耗也是比较大的。再例如：select id from t where num in(1,2,3) 对于连续的数值，能用between就不要用in了；再或者使用连接来替换。

**3.select语句务必指明字段名称**

SELECT*增加很多不必要的消耗（CPU、IO、内存、网络带宽）；增加了使用覆盖索引的可能性；当表结构发生改变时，前断也需要更新。所以要求直接在select后面接上字段名。

**4.当只需要一条数据的时候，使用limit 1**

这是为了使EXPLAIN中type列达到const类型

**5、如果排序字段没有用到索引，就尽量少排序**

**6、如果限制条件中其他字段没有索引，尽量少用or**

or两边的字段中，如果有一个不是索引字段，而其他条件也不是索引字段，会造成该查询不走索引的情况。很多时候使用union all或者是union（必要的时候）的方式来代替“or”会得到更好的效果。

**7、尽量用union all代替union**

union和union all的差异主要是前者需要将结果集合并后再进行唯一性过滤操作，这就会涉及到排序，增加大量的CPU运算，加大资源消耗及延迟。当然，union all的前提条件是两个结果集没有重复数据。

**8、不使用ORDER BY RAND()**

```
select` `id ``from` ````dynamic``` ``order` `by` `rand() limit 1000;
```

上面的SQL语句，可优化为：

```
select` `id ``from` ````dynamic``` t1 ``join` `(``select` `rand() * (``select` `max``(id) ``from` ````dynamic```) ``as` `nid) t2 ``on` `t1.id > t2.nidlimit 1000;
```

**9、区分in和exists、not in和not exists**

```
select` `* ``from` `表A ``where` `id ``in` `(``select` `id ``from` `表B)
```

上面SQL语句相当于

```
select` `* ``from` `表A ``where` `exists(``select` `* ``from` `表B ``where` `表B.id=表A.id)
```

区分in和exists主要是造成了驱动顺序的改变（这是性能变化的关键），如果是exists，那么以外层表为驱动表，先被访问，如果是IN，那么先执行子查询。所以IN适合于外表大而内表小的情况；EXISTS适合于外表小而内表大的情况。

关于not in和not exists，推荐使用not exists，不仅仅是效率问题，not in可能存在逻辑问题。如何高效的写出一个替代not exists的SQL语句？

原SQL语句：

```
select` `colname … ``from` `A表 ``where` `a.id ``not` `in` `(``select` `b.id ``from` `B表)
```

高效的SQL语句：

```
select` `colname … ``from` `A表 ``Left` `join` `B表 ``on` `where` `a.id = b.id ``where` `b.id ``is` `null
```

取出的结果集如下图表示，A表不在B表中的数据：

![img](https://img.jbzj.com/file_images/article/202203/2022316103047559.jpg?2022216103053)



**10、使用合理的分页方式以提高分页的效率**

```
select` `id,``name` `from` `product limit 866613, 20
```

使用上述SQL语句做分页的时候，可能有人会发现，随着表数据量的增加，直接使用limit分页查询会越来越慢。

优化的方法如下：可以取前一页的最大行数的id，然后根据这个最大的id来限制下一页的起点。比如此列中，上一页最大的id是866612。SQL可以采用如下的写法：

```
select` `id,``name` `from` `product ``where` `id> 866612 limit 20
```

**11、分段查询**

在一些用户选择页面中，可能一些用户选择的时间范围过大，造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序，分段进行查询，循环遍历，将结果合并处理进行展示。

**12、避免在where子句中对字段进行null值判断**

对于null的判断会导致引擎放弃使用索引而进行全表扫描。

**13、不建议使用%前缀模糊查询**

例如LIKE“%name”或者LIKE“%name%”，这种查询会导致索引失效而进行全表扫描。但是可以使用LIKE “name%”。

**14、避免在where子句中对字段进行表达式操作**

比如：

```
select` `user_id,user_project ``from` `user_base ``where` `age*2=36;
```

中对字段就行了算术运算，这会造成引擎放弃使用索引，建议改成：

```
select` `user_id,user_project ``from` `user_base ``where` `age=36/2;
```

**15、避免隐式类型转换**

where子句中出现column字段的类型和传入的参数类型不一致的时候发生的类型转换，建议先确定where中的参数类型。

**16、对于联合索引来说，要遵守最左前缀法则**

举列来说索引含有字段id、name、school，可以直接用id字段，也可以id、name这样的顺序，但是name;school都无法使用这个索引。所以在创建联合索引的时候一定要注意索引字段顺序，常用的查询字段放在最前面。

**17、必要时可以使用force index来强制查询走某个索引**

有的时候MySQL优化器采取它认为合适的索引来检索SQL语句，但是可能它所采用的索引并不是我们想要的。这时就可以采用forceindex来强制优化器使用我们制定的索引。

**18、注意范围查询语句**

对于联合索引来说，如果存在范围查询，比如between、>、<等条件时，会造成后面的索引字段失效。

**19、关于JOIN优化**

# 9. 数据结构

## 9.1 HashMap

### 9.1.1为什么使用红黑树

hashmap使用红黑树的原因是：这样可以利用链表对内存的使用率以及红黑树的高效检索，是一种很有效率的数据结构。AVL树是一种高度平衡的二叉树，所以查找的非常高，但是，有利就有弊，AVL树为了维持这种高度的平衡，就要付出更多代价。每次插入、删除都要做调整，复杂、耗时。所以，hashmap用红黑树。

红黑树相比avl树，在检索的时候效率其实差不多，都是通过平衡来二分查找。但对于插入删除等操作效率提高很多。红黑树不像avl树一样追求绝对的平衡，他允许局部很少的不完全平衡，这样对于效率影响不大，但省去了很多没有必要的调平衡操作，avl树调平衡有时候代价较大，所以效率不如红黑树，在现在很多地方都是底层都是红黑树的天下啦。



# 10. Maven

## 10.1 Maven作用

- 方便快捷的管理项目依赖的资源（jar包），避免版本冲突问题
- 提供标准统一的项目结构
- 标准跨平台的自动化项目构建方式

## 10.2 依赖

排除依赖 <exclusions>

作用范围<scope> 默认compile 主程序 测试程序 打包运行都可以

## 10.3 生命周期

clean：移除上一次构建生成的文件

compile：编译项目源代码

test：使用合适的单元测试框架运行测试

package：将编译后的文件打包

install：安装项目到本地仓库

# 11. Android

## 11.1 四大组件

Android 开发的四大组件分别是：

活动（activity），用于表现功能；

服务（service），后台运行服务，不提供界面呈现；

广播接受者 （Broadcast Receive），勇于接收广播；

内容提供者（Content Provider），支持多个应用中存储和读取数据，相当于数据库。

### 11.1.1 Activity

1.定义：

Activity组件，在应用中的一个Activity可以用来表示一个界面，意思可以理解为“活动”，即一个活动开始，代表 Activity组件启动，活动结束，代表一个Activity的生命周期结束。一个Android应用必须通过Activity来运行和启动，Activity的生命周期交给系统统一管理。

2.三个基本状态：

Resumed 一个新Activity启动入栈后，它在屏幕最前端，处于栈的最顶端，此时它处于可见并可和用户交互的激活状态。

Paused 当Activity被另一个透明或者Dialog样式的Activity覆盖时的状态。此时它依旧与窗口管理器保持连接，系统继续维护其内部状态，所以它依然可见，但它己经失去了焦点故不可与用户交互。

Stopped 当Activity被另一个Activity覆盖、失去焦点并不可见时处于Stopped状态

3.七大方法

onCreate() Activity创建时第一个调用的方法,通常我们在该方法中加载布局文件，初始化UI组件，事件注册等等

onStart() 在onCreate方法之后调用，用于显示界面，但当前用户不能进行交互

onResume() 在onStart方法后调用，该方法执行完成后，用户可进行交互，当前Activity进入Resumed状态（运行状态）；当一个Paused状态的activity被重新返回时，会再次调用该方法，让Activity进入运行状态

onRestat() 当一个Stopped状态的Activity被返回时，该方法被调用，之后再调用onResume()方法进入运行状态

onPause() 当 其他Activity(透明或窗口模式)进入时，该方法会被调用，让当前Activity进入Paused状态(暂停状态)；当前Activity还可见 但不可交互，如果其他更高优先级的app需要内存时，当前Activity可能会被销毁(kill)；当前Activity被返回时会调用 onResume()方法

onStop() 当其他Activity完全覆盖该Activity时，该方法被调用，当前 Activity进入Stopped状态(停止状态)；当前Activity不可见,如果其他更高优先级的app需要内存时，当前Activity可能会 被销毁(kill)；当前Activity被返回时会调用onRestart()方法

onDestroy() 当前Activity被销毁时调用，通常在该方法中用来释放资源，当前Activity killed

#### 11.1.1.1 Activity 生命周期

| onCreate  | 表示Activity正在被创建，这也是Activity的生命周期的第一个方法。 |
| --------- | ------------------------------------------------------------ |
| onRestart | 表示Activity正在重新启动，此生命周期只有在onPause与onStop都执行过才会被调用 |
| onStart   | 表示Activity正在被启动，即将开始，此时Activity已经可见但是还没有出现在前台，还无法交互 |
| onResume  | 表示Activity已经可见并出现在前台可以与用户进行交互           |
| onPause   | 表示Activity正在停止                                         |
| onStop    | 表示Activity停止并不可见                                     |
| onDestroy | 表示Activity即将被销毁，这是Activity的最后一个回调           |

- Activity第一次启动，回调如下：onCreate -> onStart -> onResume


- 打开新Activity或按Home键：onPause->onStop


如果新的Activity的Theme为Dialog或者Translucent（透明）时不会调用onStop方法

- 再次回到Activity：onRestart->onStart->onResume


- 按Back键退出Activity：onPause->onStop->onDestroy

  

**生命周期的对应关系**
Activity的生命周期是一一对应的，比如：

onCreate - onDestroy 创建与销毁，只可能为一次调用

onStart - onStop 可见与不可见，可能为多次调用

onResum - onPause 在前台与不在前台，可能为多次调用

#### 11.1.1.2 A启动B

**正常情况**

**A启动B**

A onPause => B onCreate  => B onStart  => B onResume  => A onStop

**返回A**

B onPause => A onRestart => A onStart  => A onResume  => B onStop=> B onDestory

**Theme为Dialog或Translucent**

**A启动B**

A onPause => B onCreate  => B onStart  => B onResume

**返回A**

B onPause => A onResume  => B onStop=> B onDestory

#### 11.1.1.3 异常情况生命周期

当系统配置被更改时Activity会被销毁并重新创建，Activity的onPause、onStop、onDestroy均会被调用，同时由于Activity是异常情况下终止并销毁的系统会调用`onSaveInstanceState`方法来保存当前Activity的状态。

之后就是正常的启动流程，当然会有`onRestoreInstancesState`方法在onStart与onResume之间调用用以恢复`onSaveInstanceState`保存的状态。

### 11.1.2 Service

1.service（服务）是安卓中的四大组件之一，它通常用作在后台处理耗时的逻辑，，并且可以和其他组件进行交互。

2.生命周期

 3.启动方式：··startService（启动）；··bindService（绑定服务）

**4.startService()与bindService()区别：**

startService只是启动Service，启动它的组件（如Activity）和Service并没有关联，只有当Service调用stopSelf或者其他组件调用stopService服务才会终止。

bindService方法启动Service，其他组件可以通过回调获取Service的代理对象和Service交互，而这两方也进行了绑定，当启动方销毁时，Service也会自动进行unBind操作，当发现所有绑定都进行了unBind时才会销毁Service。

5.IntentService

内部有一个工作线程来完成耗时的操作，只需实现onHandleIntent方法即可
完成工作后会自动终止服务
如果同时执行多个任务时，会以工作队列的方式，一次执行
通过该类来完成本APP中耗时的工作

### 11.1.3 Broadcast Receive

1.BroadcastReceiver也就是"广播接收者”的意思，顾名思义，它就是用来接收来自系统和应用中的广播。在Android系统中， 广播体现在方方面面，例如当开机完成后系统会产生一条广播，接收到这条广播就能实现开机启动服务的功能：当网络状态改变时系统会产生一条广播，接收到这条 广播就能及时地做出提示和保存数据等操作；当电池电量改变时，系统会产生一条广播，接收到这条广播就能在电量低时告知用户及时保存进度，等等。

2.广播接收器的类型

Normal broadcasts：默认广播

Ordered broadcasts：有序广播

Sticky broadcasts：粘性广播

3.注册广播接收器的两种方式

静态注册：静态注册是在AndroidManifest.xml配置文件中注册

动态注册：需要在代码中动态指定广播地址并注册，通常我们是在Activity或Service注册一个广播。

4.区别:

动态注册广播接收器特点是当用来注册的Activity关掉后，广播也就失效了。

静态注册无需担忧广播接收器是否被关闭，只要设备是开启状态，广播接收器也是打开着的。也就是说哪怕app本身未启动，该app订阅的广播在触发时也会对它起作用。

### 11.1.4 ContentProvider

android平台提供了Content Provider使一个应用程序的指定数据集提供给其他应用程序。其他应用可以通过ContentResolver类从该内容提供者中获取或存入数据。

只有需要在多个应用程序间共享数据是才需要内容提供者。例如，通讯录数据被多个应用程序使用，且必须存储在一个内容提供者中。它的好处是统一数据访问方式。

ContentProvider实现数据共享。ContentProvider用于保存和获取数据，并使其对所有应用程序可见。这是不同应用程序间共享数据的唯一方式，因为android没有提供所有应用共同访问的公共存储区。

开发人员不会直接使用ContentProvider类的对象，大多数是通过ContentResolver对象实现对ContentProvider的操作。

ContentProvider使用URI来唯一标识其数据集，这里的URI以content://作为前缀，表示该数据由ContentProvider来管理。

## 11.2 六大布局

Android六大基本布局分别是：线性布局LinearLayout、表格布局TableLayout、相对布局RelativeLayout、层布局FrameLayout、绝对布局AbsoluteLayout、网格布局GridLayout。

### 11.2.1 线性布局

线性布局在开发中使用最多，具有垂直方向与水平方向的布局方式，通过设置属性“android:orientation”控制方向，

属性值垂直（vertical）和水平(horizontal)，默认水平方向。

android:gravity：内部控件对齐方式，常用属性值有center、center_vertical、center_horizontal、top、bottom、left、right等。

这个属性在布局组件RelativeLayout、TableLayout中也有使用，FrameLayout、AbsoluteLayout则没有这个属性。

center：居中显示，这里并不是表示显示在LinearLayout的中心，当LinearLayout线性方向为垂直方向时，

center表示水平居中，但是并不能垂直居中，此时等同于center_horizontal的作用；同样当线性方向为水平方向时，center表示垂直居中，等同于center_vertical。

top、bottom、left、right顾名思义为内部控件居顶、低、左、右布局。

这里要与android:layout_gravity区分开，layout_gravity是用来设置自身相对于父元素的布局。

android:layout_weight：权重，用来分配当前控件在剩余空间的大小。

使用权重一般要把分配该权重方向的长度设置为零，比如在水平方向分配权重，就把width设置为零。

### 11.2.2 RelativeLayout

相对布局可以让子控件相对于兄弟控件或父控件进行布局，可以设置子控件相对于兄弟控件

或父控件进行上下左右对齐。

RelativeLayout能替换一些嵌套视图，当我们用LinearLayout来实现一个简单的布局但又使用了过多的嵌套时，

就可以考虑使用RelativeLayout重新布局。

RelativeLayout中子控件常用属性：

1、相对于父控件，例如：android:layout_alignParentTop=“true”

android:layout_alignParentTop 控件的顶部与父控件的顶部对齐;

android:layout_alignParentBottom 控件的底部与父控件的底部对齐;

android:layout_alignParentLeft 控件的左部与父控件的左部对齐;

android:layout_alignParentRight 控件的右部与父控件的右部对齐;

2、相对给定Id控件，例如：android:layout_above=“@id/**”

android:layout_above 控件的底部置于给定ID的控件之上;

android:layout_below 控件的底部置于给定ID的控件之下;

android:layout_toLeftOf 控件的右边缘与给定ID的控件左边缘对齐;

android:layout_toRightOf 控件的左边缘与给定ID的控件右边缘对齐;

android:layout_alignBaseline 控件的baseline与给定ID的baseline对齐;

android:layout_alignTop 控件的顶部边缘与给定ID的顶部边缘对齐;

android:layout_alignBottom 控件的底部边缘与给定ID的底部边缘对齐;

android:layout_alignLeft 控件的左边缘与给定ID的左边缘对齐;

android:layout_alignRight 控件的右边缘与给定ID的右边缘对齐;

3、居中，例如：android:layout_centerInParent=“true”

android:layout_centerHorizontal 水平居中;

android:layout_centerVertical 垂直居中;

android:layout_centerInParent 父控件的中央;

相对布局的属性有点相近，如果不仔细看有可能会弄混乱，所以使用的时候要细心。

### 11.2.3 FrameLayout

帧布局或叫层布局，从屏幕左上角按照层次堆叠方式布局，后面的控件覆盖前面的控件。

该布局在开发中设计地图经常用到，因为是按层次方式布局，我们需要实现层面显示的样式时就可以

采用这种布局方式，比如我们要实现一个类似百度地图的布局，我们移动的标志是在一个图层的上面。

在普通功能的软件设计中用得也不多。

### 11.2.4 AbsoluteLayout

绝对布局也叫坐标布局，指定控件的绝对位置，简单直接，直观性强，但是手机屏幕尺寸差别较大，适应性差，Android 1.5已弃用，可以用RelativeLayout替代。



这里为了设计一个注册登陆界面，将各个控件的layout_x与layout_y依次设置了一遍，然而当前屏幕尺寸能正常显示，其他屏幕就需要重新制定布局。

其实用RelativeLayout轻松就能实现这样的效果，还不用考虑屏幕兼容性。

所以，AbsoluteLayout已成为android布局中的历史。

但是，在其他它的开发领域相对布局还是有点用的，比如机顶盒开发中的界面设计。

### 11.2.5 TableLayout

表格布局继承自LinearLayout，通过TableRow设置行，列数由TableRow中的子控件决定，直接在TableLayout中添加子控件会占据整个一行。

TableLayout常用属性：

android:shrinkColumns：设置可收缩的列，内容过多就收缩显示到第二行

android:stretchColumns：设置可伸展的列，将空白区域填充满整个列

android:collapseColumns：设置要隐藏的列

列的索引从0开始，shrinkColumns和stretchColumns可以同时设置。

子控件常用属性：

android:layout_column：第几列

android:layout_span：占据列数

### 11.2.6 GridLayout(网格布局)

作为android 4.0 后新增的一个布局,与前面介绍过的TableLayout(表格布局)其实有点大同小异;不过新增了一些东东

①跟LinearLayout(线性布局)一样,他可以设置容器中组件的对齐方式

②容器中的组件可以跨多行也可以跨多列(相比TableLayout直接放组件,占一行相比较)

因为是android 4.0新增的,API Level 14,在这个版本以前的sdk都需要导入项目。这里不解释。

常用属性:

排列对齐:

①设置组件的排列方式: android:orientation="" vertical(竖直,默认)或者horizontal(水平)

②设置组件的对齐方式: android:layout_gravity="" center,left,right,buttom

设置布局为几行几列:

①设置有多少行: android:rowCount="4" //设置网格布局有4行

②设置有多少列: android:columnCount="4" //设置网格布局有4列

设置某个组件位于几行几列

注:都是从0开始算的哦！

①组件在第几行: android:layout_row = "1" //设置组件位于第二行

②组件在第几列: android:layout_column = "2" //设置该组件位于第三列

设置某个组件横跨几行几列:

①横跨几行: android:layout_rowSpan = "2" //纵向横跨2行

②横跨几列: android:layout_columnSpan = "3" //横向横跨2列



用法总结:
①GridLayout使用虚细线将布局划分为行,列和单元格,同时也支持在行,列上进行交错排列

②使用流程:

step 1:先定义组件的对其方式 android:orientation 水平或者竖直

step 2:设置组件所在的行或者列,记得是从0开始算的

step 3:设置组件横跨几行或者几列;设置完毕后,需要在设置一个填充:android:layout_gravity = "fill"

## 11.3 内存泄漏

### 11.3.1 检测和定位

使用Profiler来查看内存泄漏

Allocations：Java堆中的实例个数

Native Size：native层分配的内存大小。

Shallow Size：Java堆中分配实际大小

Retained Size：这个类的所有实例保留的内存总大小（并非实际大小）

使用Android LeakCanary

### 11.3.2 解决办法

在Android程序开发中，当一个对象已经不需要再使用了，本该被回收时，而另外一个正在使用的对象持有它的引用从而导致它不能被回收，这就导致本该被回收的对象不能被回收而停留在堆内存中，内存泄漏就产生了。

内存泄漏有什么影响呢?它是造成应用程序OOM的主要原因之一。由于Android系统为每个应用程序分配的内存有限，当一个应用中产生的内存泄漏比较多时，就难免会导致应用所需要的内存超过这个系统分配的内存限额，这就造成了内存溢出而导致应用Crash。

了解了内存泄漏的原因及影响后，我们需要做的就是掌握常见的内存泄漏，并在以后的Android程序开发中，尽量避免它。下面小编搜罗了5个Android开发中比较常见的内存泄漏问题及解决办法，分享给大家，一起来看看吧。

一、单例造成的内存泄漏

Android的单例模式非常受开发者的喜爱，不过使用的不恰当的话也会造成内存泄漏。因为单例的静态特性使得单例的生命周期和应用的生命周期一样长，这就说明了如果一个对象已经不需要使用了，而单例对象还持有该对象的引用，那么这个对象将不能被正常回收，这就导致了内存泄漏。

这是一个普通的单例模式，当创建这个单例的时候，由于需要传入一个Context，所以这个Context的生命周期的长短至关重要：

1、传入的是Application的Context：这将没有任何问题，因为单例的生命周期和Application的一样长 ;

2、传入的是Activity的Context：当这个Context所对应的Activity退出时，由于该Context和Activity的生命周期一样长(Activity间接继承于Context)，所以当前Activity退出时它的内存并不会被回收，因为单例对象持有该Activity的引用。

所以正确的单例应该修改为下面这种方式：

这样不管传入什么Context最终将使用Application的Context，而单例的生命周期和应用的一样长，这样就防止了内存泄漏。

二、非静态内部类创建静态实例造成的内存泄漏

有的时候我们可能会在启动频繁的Activity中，为了避免重复创建相同的数据资源，会出现这种写法：

这样就在Activity内部创建了一个非静态内部类的单例，每次启动Activity时都会使用该单例的数据，这样虽然避免了资源的重复创建，不过这种写法却会造成内存泄漏，因为非静态内部类默认会持有外部类的引用，而又使用了该非静态内部类创建了一个静态的实例，该实例的生命周期和应用的一样长，这就导致了该静态实例一直会持有该Activity的引用，导致Activity的内存资源不能正常回收。正确的做法为：

将该内部类设为静态内部类或将该内部类抽取出来封装成一个单例，如果需要使用Context，请使用ApplicationContext 。

三、Handler造成的内存泄漏

Handler的使用造成的内存泄漏问题应该说最为常见了，平时在处理网络任务或者封装一些请求回调等api都应该会借助Handler来处理，对于Handler的使用代码编写一不规范即有可能造成内存泄漏，如下示例：

这种创建Handler的方式会造成内存泄漏，由于mHandler是Handler的非静态匿名内部类的实例，所以它持有外部类Activity的引用，我们知道消息队列是在一个Looper线程中不断轮询处理消息，那么当这个Activity退出时消息队列中还有未处理的消息或者正在处理消息，而消息队列中的Message持有mHandler实例的引用，mHandler又持有Activity的引用，所以导致该Activity的内存资源无法及时回收，引发内存泄漏，所以另外一种做法为：

创建一个静态Handler内部类，然后对Handler持有的对象使用弱引用，这样在回收时也可以回收Handler持有的对象，这样虽然避免了Activity泄漏，不过Looper线程的消息队列中还是可能会有待处理的消息，所以我们在Activity的Destroy时或者Stop时应该移除消息队列中的消息，更准确的做法如下：

使用mHandler.removeCallbacksAndMessages(null);是移除消息队列中所有消息和所有的Runnable。当然也可以使用mHandler.removeCallbacks();或mHandler.removeMessages()；来移除指定的Runnable和Message。

四、线程造成的内存泄漏

对于线程造成的内存泄漏，也是平时比较常见的，如下这两个示例可能每个人都这样写过：

上面的异步任务和Runnable都是一个匿名内部类，因此它们对当前Activity都有一个隐式引用。如果Activity在销毁之前，任务还未完成， 那么将导致Activity的内存资源无法回收，造成内存泄漏。正确的做法还是使用静态内部类的方式，如下：

这样就避免了Activity的内存资源泄漏，当然在Activity销毁时候也应该取消相应的任务AsyncTask::cancel()，避免任务在后台执行浪费资源。

五、资源未关闭造成的内存泄漏

对于使用了BraodcastReceiver，ContentObserver，File，Cursor，Stream，Bitmap等资源的使用，应该在Activity销毁时及时关闭或者注销，否则这些资源将不会被回收，造成内存泄漏。

## 11.4 Activity启动模式

**1，standard**

默认模式，可以不用写配置。在这个模式下，都会默认创建一个新的实例。因此，在这种模式下，可以有多个相同的实例，也允许多个相同Activity叠加。

例如：

若我有一个Activity名为A1, 上面有一个按钮可跳转到A1。那么如果我点击按钮，便会新启一个Activity A1叠在刚才的A1之上，再点击，又会再新启一个在它之上……

点back键会依照栈顺序依次退出。

**2，singleTop**

可以有多个实例，但是不允许多个相同Activity叠加。即，如果Activity在栈顶的时候，启动相同的Activity，不会创建新的实例，而会调用其onNewIntent方法。

例如：

若我有两个Activity名为B1,B2,两个Activity内容功能完全相同，都有两个按钮可以跳到B1或者B2，唯一不同的是B1为standard，B2为singleTop。

若我意图打开的顺序为B1->B2->B2，则实际打开的顺序为B1->B2（后一次意图打开B2，实际只调用了前一个的onNewIntent方法）

若我意图打开的顺序为B1->B2->B1->B2，则实际打开的顺序与意图的一致，为B1->B2->B1->B2。

**3，singleTask**

只有一个实例。在同一个应用程序中启动他的时候，若Activity不存在，则会在当前task创建一个新的实例，若存在，则会把task中在其之上的其它Activity destory掉并调用它的onNewIntent方法。

如果是在别的应用程序中启动它，则会新建一个task，并在该task中启动这个Activity，singleTask允许别的Activity与其在一个task中共存，也就是说，如果我在这个singleTask的实例中再打开新的Activity，这个新的Activity还是会在singleTask的实例的task中。

例如：

若我的应用程序中有三个Activity,C1,C2,C3，三个Activity可互相启动，其中C2为singleTask模式，那么，无论我在这个程序中如何点击启动，如：C1->C2->C3->C2->C3->C1-C2，C1,C3可能存在多个实例，但是C2只会存在一个，并且这三个Activity都在同一个task里面。

但是C1->C2->C3->C2->C3->C1-C2，这样的操作过程实际应该是如下这样的，因为singleTask会把task中在其之上的其它Activity destory掉。

操作：C1->C2     C1->C2->C3     C1->C2->C3->C2      C1->C2->C3->C2->C3->C1      C1->C2->C3->C2->C3->C1-C2

实际：C1->C2     C1->C2->C3     C1->C2               C1->C2->C3->C1               C1->C2

若是别的应用程序打开C2，则会新启一个task。

如别的应用Other中有一个activity，taskId为200，从它打开C2，则C2的taskIdI不会为200，例如C2的taskId为201，那么再从C2打开C1、C3，则C2、C3的taskId仍为201。

注意：如果此时你点击home，然后再打开Other，发现这时显示的肯定会是Other应用中的内容，而不会是我们应用中的C1 C2 C3中的其中一个。

**4，singleInstance**

只有一个实例，并且这个实例独立运行在一个task中，这个task只有这个实例，不允许有别的Activity存在。

例如：

程序有三个ActivityD1,D2,D3，三个Activity可互相启动，其中D2为singleInstance模式。那么程序从D1开始运行，假设D1的taskId为200，那么从D1启动D2时，D2会新启动一个task，即D2与D1不在一个task中运行。假设D2的taskId为201，再从D2启动D3时，D3的taskId为200，也就是说它被压到了D1启动的任务栈中。

若是在别的应用程序打开D2，假设Other的taskId为200，打开D2，D2会新建一个task运行，假设它的taskId为201，那么如果这时再从D2启动D1或者D3，则又会再创建一个task，因此，若操作步骤为other->D2->D1，这过程就涉及到了3个task了。

设置Activity的启动模式，只需要在AndroidManifest.xml里对应的<activity>标签设置Android:launchMode属性，例如：

android:name=".A1" 

android:launchMode="standard"/> 
